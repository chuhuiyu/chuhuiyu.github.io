<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://chuhuiyu.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://chuhuiyu.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-26T20:50:27+00:00</updated><id>https://chuhuiyu.github.io/feed.xml</id><title type="html">Huiyu Chu</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Use LogBert to do log anomaly detection</title><link href="https://chuhuiyu.github.io/blog/2023/Bert/" rel="alternate" type="text/html" title="Use LogBert to do log anomaly detection"/><published>2023-12-08T02:14:17+00:00</published><updated>2023-12-08T02:14:17+00:00</updated><id>https://chuhuiyu.github.io/blog/2023/Bert</id><content type="html" xml:base="https://chuhuiyu.github.io/blog/2023/Bert/"><![CDATA[<h1 id="1-general-knowledge-about-bert"><strong>1. General Knowledge about Bert</strong></h1> <p>Reference:</p> <ol> <li><a href="https://www.kaggle.com/code/neerajmohan/fine-tuning-bert-for-text-classification">Fine-tuning BERT for Text classification in Kaggle</a></li> <li>Natural Language Processing IN2361 by Prof. Dr. Georg Groh</li> </ol> <h2 id="bert-bidirectional-encoder-representations-from-transformers"><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong></h2> <p>Language modeling is a common method of pretraining on unlabeled text (self supervised learning). Most of the language models learned by iteratively predicting next word in a sequence auto regressively across enormous data sets of text like wikepedia. This can be left to right, right to left or bi-directional.</p> <p>There are two strategies of applying pretrained language representations to downstream tasks:</p> <ol> <li>Feature based approach</li> <li>Fine tuning approach</li> </ol> <p>The feauture based approach, such as <strong>ELMo</strong> uses task specific architectures that include the pretrained representations as additional features.</p> <p>The fine tuning approach, such as <strong>OpenAI GPT</strong>, introduces minimal task specific parameters, and is trained on the downstream task by fine tuning all the pretrained parameters.</p> <p>BERT model can be used for both the approaches. BERT reformulates the language modeling pretrained task of iteratively predicting the next word in sequence to instead <strong>incorporate bidirectional context and predict mask of intermediate tokens of the sequence and predict the mask token.</strong> BERT presented a new self supervised learning task for pretaining transformers in order to fine tune them for different tasks. They major difference between BERT and prior methods of pretraining transformer models is using the bidirectional context of language modeling. Most of the models either move left to right or right to left to predict next word in sequence, where BERT tries to learn intermediate tokens (by MASK), making the name Bidirectional Encoder.</p> <p>BERT uses Masked language model and also use “Next sentence prediction” task.</p> <p>BERT uses 3 embeddings to compute the input representations. They are token embeddings, segment embeddings and position embeddings.</p> <p>BERT Transformer will preserve the length of the (dimention of the) input. The final output will take this vector and pass these to seperate tasks (classification, in this case).</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bert/Untitled-480.webp 480w,/assets/img/bert/Untitled-800.webp 800w,/assets/img/bert/Untitled-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/bert/Untitled.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Bert Training Process with masked language model</p> <h2 id="bert-for-classification-logbert-didnt-use-this-strategy"><strong>BERT for Classification [LogBert didn’t use this strategy]</strong></h2> <p>BERT consists of stacked encoder layers. Just like the input of encoder of the transformer model, BERT model takes the sequence of numeric representation of the tokens as input. For classification tasks, we must prepend the special [CLS] token (classification token)to the beginning of every sentence.</p> <p>Encoder block of transformer outputs a vector with same length as of input. First position of the vector, corresponding to the [CLS] token, can now be used as the input for a classifier.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bert/Untitled1-480.webp 480w,/assets/img/bert/Untitled1-800.webp 800w,/assets/img/bert/Untitled1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/bert/Untitled1.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h1 id="2-how-to-use-masked-langauge-model-to-do-anomaly-detection-logbert-method"><strong>2. How to use Masked Langauge Model to do Anomaly Detection [LogBert method]</strong></h1> <p>[Guo, Haixuan, Shuhan Yuan, and Xintao Wu. “Logbert: Log anomaly detection via bert.” <em>2021 international joint conference on neural networks (IJCNN)</em>. IEEE, 2021.]</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bert/Untitled2-480.webp 480w,/assets/img/bert/Untitled2-800.webp 800w,/assets/img/bert/Untitled2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/bert/Untitled2.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>General Idea:</p> <ul> <li>Finetune the pretrained Bert model on the normal log lines by training on the masked language model.</li> <li>After this finetuning process, the model should predict the masked words in normal log lines very well. Since it didn’t see any abnormal logs before, it should predict the masked words in abnormal log lines very badly.</li> <li>From this point, we can seperate normal log lines and abnormal lines by looking at the performance of the model, which is reflected by the entropy loss value of prediction.</li> </ul> <h1 id="3-logbert-in-logai---the-whole-pipeline"><strong>3. LogBert in LogAI - the whole pipeline</strong></h1> <h2 id="31-load-opensearch-indices-preprocessing-and-save-as-pandas-feather-format"><strong>3.1 Load Opensearch indices, preprocessing and save as pandas “feather” format</strong></h2> <p>the util function that load data in range:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_data_range</span><span class="p">(</span><span class="n">index_name</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">client</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">client</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">client</span> <span class="o">=</span> <span class="nc">OpenSearch</span><span class="p">(</span>
            <span class="n">hosts</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">https://10.11.40.114:9200</span><span class="sh">'</span><span class="p">],</span>
            <span class="n">use_ssl</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">verify_certs</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
            <span class="n">http_auth</span><span class="o">=</span><span class="p">(</span><span class="sh">'</span><span class="s">admin</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">admin</span><span class="sh">'</span><span class="p">),</span>
            <span class="n">timeout</span><span class="o">=</span><span class="mi">60</span>
        <span class="p">)</span>
    <span class="n">max_index</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">indices</span><span class="p">.</span><span class="nf">stats</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index_name</span><span class="p">)[</span><span class="sh">'</span><span class="s">_all</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">primaries</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">docs</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">start</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">max_index</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="n">max_index</span><span class="p">)</span>

    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Loading data from index </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">start</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> until index </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">end</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> size is </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">query</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">from</span><span class="sh">"</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">size</span><span class="sh">"</span><span class="p">:</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">query</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">match_all</span><span class="sh">"</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
    <span class="p">}</span>

    <span class="n">search_results</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="n">query</span><span class="p">)</span>

<span class="c1"># Extract and convert the documents to a Pandas DataFrame
</span>    <span class="n">documents</span> <span class="o">=</span> <span class="n">search_results</span><span class="p">[</span><span class="sh">"</span><span class="s">hits</span><span class="sh">"</span><span class="p">][</span><span class="sh">"</span><span class="s">hits</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span><span class="p">[</span><span class="sh">'</span><span class="s">_source</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div> <p>init opensearch client, read the index in pieces and concat them together and save them:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">warnings</span>
<span class="kn">from</span> <span class="n">collections.abc</span> <span class="kn">import</span> <span class="n">MutableMapping</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">opensearchpy</span> <span class="kn">import</span> <span class="n">OpenSearch</span>
<span class="kn">import</span> <span class="n">math</span>
<span class="kn">import</span> <span class="n">pickle</span>
<span class="kn">import</span> <span class="n">utils</span>

<span class="n">client</span> <span class="o">=</span> <span class="nc">OpenSearch</span><span class="p">(</span>
    <span class="n">hosts</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">https://10.11.40.114:9200</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">use_ssl</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">verify_certs</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">http_auth</span><span class="o">=</span><span class="p">(</span><span class="sh">'</span><span class="s">admin</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">admin</span><span class="sh">'</span><span class="p">),</span>
    <span class="n">timeout</span><span class="o">=</span><span class="mi">60</span>
<span class="p">)</span>

<span class="n">index_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">2023-09-05_system_v4</span><span class="sh">"</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">indices</span><span class="p">.</span><span class="nf">stats</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index_name</span><span class="p">)[</span><span class="sh">'</span><span class="s">_all</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">primaries</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">docs</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">]</span>
<span class="n">iteration_size</span> <span class="o">=</span> <span class="mi">500000</span>
<span class="n">dataset_iterations</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">ceil</span><span class="p">((</span><span class="n">size</span> <span class="o">/</span> <span class="n">iteration_size</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">df size: </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> iterations: </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">dataset_iterations</span><span class="p">))</span>

<span class="n">df_save</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span>  <span class="n">dataset_iterations</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Iteration </span><span class="sh">"</span> <span class="o">+</span>  <span class="nf">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> of </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">dataset_iterations</span><span class="p">))</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">utils</span><span class="p">.</span><span class="nf">load_data_range</span><span class="p">(</span><span class="n">index_name</span><span class="p">,</span> <span class="p">(</span><span class="n">iteration_size</span> <span class="o">*</span> <span class="n">i</span><span class="p">),</span> <span class="p">((</span><span class="n">iteration_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">client</span><span class="p">)</span>
    <span class="n">df_save</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">df_save</span><span class="p">,</span> <span class="n">df</span><span class="p">])</span>

<span class="n">df_save</span> <span class="o">=</span> <span class="n">df_save</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="n">df_save</span><span class="p">.</span><span class="nf">to_feather</span><span class="p">(</span><span class="sh">'</span><span class="s">filename.feather</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>some preprocessing on the raw opensearch data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="c1">## read saved feather data
</span><span class="n">training_df1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_feather</span><span class="p">(</span><span class="sh">'</span><span class="s">filename1.feather</span><span class="sh">'</span><span class="p">)</span>
<span class="n">training_df2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_feather</span><span class="p">(</span><span class="sh">'</span><span class="s">filename2.feather</span><span class="sh">'</span><span class="p">)</span>
<span class="n">testing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_feather</span><span class="p">(</span><span class="sh">'</span><span class="s">filename3.feather</span><span class="sh">'</span><span class="p">)</span>

<span class="c1">## rename logline column from "desciption" to "logline", because logai uses constant## "logline" as the default column name of logline.
</span>
<span class="n">testing_df</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">},</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">training_df1</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">},</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">training_df2</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">},</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1">## set span_id
</span><span class="n">testing_df</span><span class="p">[</span><span class="sh">'</span><span class="s">span_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">testing_df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span>
<span class="n">training_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">span_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span>
<span class="n">training_df2</span><span class="p">[</span><span class="sh">'</span><span class="s">span_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_df2</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span>

<span class="c1">## label anomalies, note that the training process is purely unsupervised and## doesn't require labels, but it seems necessary to assign labels column to the## dataframe. Also it helps visualize the result later if you want to see the## loglines that you are interested in (just lable those interesting log lines with 1)## In normal cases, just set the whole columns 0 values
</span><span class="n">training_df1</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">training_df2</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">testing_df</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">testing_df</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="k">if</span> <span class="sh">"</span><span class="s">ABEND</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">]:</span>
        <span class="n">testing_df</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="sh">"</span><span class="s">ERROR</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">]:</span>
        <span class="n">testing_df</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="sh">"</span><span class="s">WARN</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">]:</span>
        <span class="n">testing_df</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">## concat 2 training dataframe as one and reset index, span_id
</span><span class="n">training_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">training_df1</span><span class="p">,</span><span class="n">training_df2</span><span class="p">]).</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="n">training_df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_df</span><span class="p">.</span><span class="n">index</span>
<span class="n">training_df</span><span class="p">[</span><span class="sh">'</span><span class="s">span_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span>
<span class="n">training_df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">level_0</span><span class="sh">'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">testing_df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">testing_df</span><span class="p">.</span><span class="n">index</span>
<span class="n">testing_df</span><span class="p">[</span><span class="sh">'</span><span class="s">span_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">testing_df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span>

<span class="c1">## save them again
</span><span class="n">testing_df</span><span class="p">.</span><span class="nf">to_pickle</span><span class="p">(</span><span class="sh">'</span><span class="s">testing_df.pkl</span><span class="sh">'</span><span class="p">)</span>
<span class="n">training_df</span><span class="p">.</span><span class="nf">to_pickle</span><span class="p">(</span><span class="sh">'</span><span class="s">training_df.pkl</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <h2 id="32-custom-preprocessor"><strong>3.2 Custom preprocessor</strong></h2> <p>read the saved pkl from the last step:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">testing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_pickle</span><span class="p">(</span><span class="sh">'</span><span class="s">testing_df.pkl</span><span class="sh">'</span><span class="p">)</span>
<span class="n">training_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_pickle</span><span class="p">(</span><span class="sh">'</span><span class="s">training_df.pkl</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>To encode special values (like IP, HEX value, INT value, etc.) into special tokens and preprocess , we need to override 2 methods from OpenSetPreprocessor, specify the preprocessor_config, and set special tokens in the tokenizer.</p> <h3 id="321-override-2-methods-from-opensetpreprocessor">3.2.1 Override 2 methods from OpenSetPreprocessor</h3> <ul> <li>_get_ids(self, logrecord) → pd.Series</li> <li>_get_labels(self, logrecord)</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">logai.preprocess.openset_preprocessor</span> <span class="kn">import</span> <span class="n">OpenSetPreprocessor</span>

<span class="k">class</span> <span class="nc">SDMLOG_Preprocessor</span><span class="p">(</span><span class="n">OpenSetPreprocessor</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Custom preprocessor for Open log dataset BGL.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">PreprocessorConfig</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_ids</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logrecord</span><span class="p">:</span> <span class="n">LogRecordObject</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Get ids of loglines.
        :param logrecord:  logrecord object containing the BGL data.
        :return: pd.Series object containing the ids of the loglines.
        </span><span class="sh">"""</span>
        <span class="n">ids</span> <span class="o">=</span> <span class="n">logrecord</span><span class="p">.</span><span class="n">span_id</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">SPAN_ID</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ids</span>

    <span class="k">def</span> <span class="nf">_get_labels</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logrecord</span><span class="p">:</span> <span class="n">LogRecordObject</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Get anomaly detection labels of loglines.
        :param logrecord: logrecord object containing the BGL data.
        :return:pd.Series object containing the labels of the loglines.
        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="n">logrecord</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="nc">SDMLOG_Preprocessor</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">preprocessor_config</span><span class="p">)</span>
<span class="n">preprocessed_filepath</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sh">'</span><span class="s">filename.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">logrecord</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="p">.</span><span class="nf">clean_log</span><span class="p">(</span><span class="n">logrecord</span><span class="p">)</span>
<span class="n">logrecord</span><span class="p">.</span><span class="nf">save_to_csv</span><span class="p">(</span><span class="n">preprocessed_filepath</span><span class="p">)</span>

</code></pre></div></div> <h3 id="322-specify-preprocessor-related-config">3.2.2 specify preprocessor-related config</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">preprocessor_config</span><span class="pi">:</span>
  <span class="na">custom_delimiters_regex</span><span class="pi">:</span>
              <span class="pi">[</span><span class="s1">'</span><span class="s">:'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">,'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">='</span><span class="pi">,</span> <span class="s1">'</span><span class="s">\\t'</span><span class="pi">]</span>
  <span class="na">custom_replace_list</span><span class="pi">:</span> <span class="pi">[</span>
              <span class="pi">[</span><span class="s1">'</span><span class="s">(0x)[0-9a-zA-Z]+'</span><span class="pi">,</span> <span class="s1">'</span><span class="nv"> </span><span class="s">HEX</span><span class="nv"> </span><span class="s">'</span><span class="pi">],</span>
              <span class="pi">[</span><span class="s1">'</span><span class="s">((?![A-Za-z]{8}|\\d{8})[A-Za-z\\d]{8})'</span><span class="pi">,</span> <span class="s1">'</span><span class="nv"> </span><span class="s">ALPHANUM</span><span class="nv"> </span><span class="s">'</span><span class="pi">],</span>
              <span class="pi">[</span><span class="s1">'</span><span class="s">\\d+.\\d+.\\d+.\\d+'</span><span class="pi">,</span> <span class="s1">'</span><span class="nv"> </span><span class="s">IP</span><span class="nv"> </span><span class="s">'</span><span class="pi">],</span>
              <span class="pi">[</span><span class="s1">'</span><span class="s">\\d+'</span><span class="pi">,</span> <span class="s1">'</span><span class="nv"> </span><span class="s">INT</span><span class="nv"> </span><span class="s">'</span><span class="pi">]</span>
          <span class="pi">]</span>

</code></pre></div></div> <h3 id="323-set-special-tokens-in-the-tokenizer-config-which-should-be-the-same-list-of-custom_replace_list-in-the-preprocessor_config">3.2.3 set special tokens in the tokenizer config, which should be the same list of “custom_replace_list” in the preprocessor_config</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">log_vectorizer_config</span><span class="pi">:</span>
  <span class="na">algo_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">logbert"</span>
  <span class="na">algo_param</span><span class="pi">:</span>
    <span class="na">model_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bert-base-cased"</span>
    <span class="na">max_token_len</span><span class="pi">:</span> <span class="m">120</span>
    <span class="na">custom_tokens</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">ALPHANUM"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">IP"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">HEX"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">INT"</span><span class="pi">]</span>
    <span class="na">output_dir</span><span class="pi">:</span> <span class="s2">"</span><span class="s">outputdir"</span>
    <span class="na">tokenizer_dirname</span><span class="pi">:</span> <span class="s2">"</span><span class="s">logbert_tokTenizer"</span>
</code></pre></div></div> <h2 id="33-split-the-training-validation-and-testing-dataset"><strong>3.3 Split the training, validation and testing dataset</strong></h2> <p>use sklearn.model_selection train_test_split:</p> <p>here I split the logrecord_training into 99% training data, and 1% evaluation data, for the sake of adequate amount of training data and quick evaluation</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">train_filepath</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sh">'</span><span class="s">train.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">dev_filepath</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sh">'</span><span class="s">dev.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">test_filepath</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sh">'</span><span class="s">test.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="n">train_ids</span><span class="p">,</span> <span class="n">dev_ids</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">dev_labels</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span>
    <span class="n">logrecord_training</span><span class="p">.</span><span class="n">span_id</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">SPAN_ID</span><span class="p">],</span>
    <span class="n">logrecord_training</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">],</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">indices_train</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span>
        <span class="n">logrecord_training</span><span class="p">.</span><span class="n">span_id</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span>
            <span class="n">logrecord_training</span><span class="p">.</span><span class="n">span_id</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">SPAN_ID</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">train_ids</span><span class="p">)</span>
        <span class="p">].</span><span class="n">index</span>
    <span class="p">)</span>
<span class="n">indices_dev</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span>
    <span class="n">logrecord_training</span><span class="p">.</span><span class="n">span_id</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">logrecord_training</span><span class="p">.</span><span class="n">span_id</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">SPAN_ID</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">dev_ids</span><span class="p">)].</span><span class="n">index</span>
<span class="p">)</span>
<span class="n">indices_test</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span>
    <span class="n">logrecord_testing</span><span class="p">.</span><span class="n">span_id</span><span class="p">.</span><span class="n">index</span>
<span class="p">)</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">logrecord_training</span><span class="p">.</span><span class="nf">select_by_index</span><span class="p">(</span><span class="n">indices_train</span><span class="p">)</span>
<span class="n">dev_data</span> <span class="o">=</span> <span class="n">logrecord_training</span><span class="p">.</span><span class="nf">select_by_index</span><span class="p">(</span><span class="n">indices_dev</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">logrecord_testing</span><span class="p">.</span><span class="nf">select_by_index</span><span class="p">(</span><span class="n">indices_test</span><span class="p">)</span>
<span class="c1">#train_data.save_to_csv(train_filepath)#dev_data.save_to_csv(dev_filepath)#test_data.save_to_csv(test_filepath)
</span><span class="nf">print </span><span class="p">(</span><span class="sh">'</span><span class="s">Train/Dev/Test Anomalous</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">train_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]),</span>
                                   <span class="nf">len</span><span class="p">(</span><span class="n">dev_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">dev_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]),</span>
                                   <span class="nf">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">test_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]))</span>
<span class="nf">print </span><span class="p">(</span><span class="sh">'</span><span class="s">Train/Dev/Test Normal</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">train_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]),</span>
                                   <span class="nf">len</span><span class="p">(</span><span class="n">dev_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">dev_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]),</span>
                                   <span class="nf">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">test_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]))</span>
</code></pre></div></div> <h2 id="34-train-bert-vectorizer"><strong>3.4 Train Bert vectorizer</strong></h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vectorizer</span> <span class="o">=</span> <span class="nc">LogVectorizer</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">log_vectorizer_config</span><span class="p">)</span>
<span class="n">vectorizer</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">dev_features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">dev_data</span><span class="p">)</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</code></pre></div></div> <h2 id="35-bert-model-training"><strong>3.5 Bert model training</strong></h2> <p>related config:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="na">nn_anomaly_detection_config</span><span class="pi">:</span>
      <span class="na">algo_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">logbert"</span>
      <span class="na">algo_params</span><span class="pi">:</span>
          <span class="na">model_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bert-base-cased"</span>
          <span class="na">learning_rate</span><span class="pi">:</span> <span class="m">0.00005</span>
          <span class="na">num_train_epochs</span><span class="pi">:</span> <span class="m">1</span>
          <span class="na">per_device_train_batch_size</span><span class="pi">:</span> <span class="m">32</span>
          <span class="na">max_token_len</span><span class="pi">:</span> <span class="m">120</span>
          <span class="na">save_steps</span><span class="pi">:</span> <span class="m">1000</span>
          <span class="na">eval_steps</span><span class="pi">:</span> <span class="m">1000</span>
          <span class="na">tokenizer_dirpath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bert-base-cased_tokenizer"</span>
          <span class="na">output_dir</span><span class="pi">:</span> <span class="s2">"</span><span class="s">outputdir"</span>
          <span class="s">pretrain_from_scratch:False</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">anomaly_detector</span> <span class="o">=</span> <span class="nc">NNAnomalyDetector</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">nn_anomaly_detection_config</span><span class="p">)</span>
<span class="n">anomaly_detector</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">dev_features</span><span class="p">)</span>
</code></pre></div></div> <h2 id="36-bert-model-testing"><strong>3.6 Bert model testing</strong></h2> <p>related config:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="na">nn_anomaly_detection_config</span><span class="pi">:</span>
      <span class="na">algo_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">logbert"</span>
      <span class="na">algo_params</span><span class="pi">:</span>
          <span class="na">model_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bert-base-cased"</span>
          <span class="na">per_device_eval_batch_size</span><span class="pi">:</span> <span class="m">32</span>
          <span class="na">eval_accumulation_steps</span><span class="pi">:</span> <span class="m">284</span>
          <span class="na">mask_ngram</span><span class="pi">:</span> <span class="m">8</span>
          <span class="na">tokenizer_dirpath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bert-base-cased_tokenizer"</span>
          <span class="na">output_dir</span><span class="pi">:</span> <span class="s2">"</span><span class="s">outputdir"</span>
          <span class="na">num_eval_shards</span><span class="pi">:</span> <span class="m">100</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">anomaly_detector</span> <span class="o">=</span> <span class="nc">NNAnomalyDetector</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">nn_anomaly_detection_config</span><span class="p">)</span>
<span class="n">predict_results</span> <span class="o">=</span> <span class="n">anomaly_detector</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">test_features_piece</span><span class="p">)</span>
<span class="nf">print </span><span class="p">(</span><span class="n">predict_results</span><span class="p">)</span>
</code></pre></div></div> <h2 id="37-output-intepretation"><strong>3.7 Output Intepretation</strong></h2> <p>take partitioned logs as example, here is the data flow:</p> <ul> <li>prediction.feather <ul> <li>406105x19cols</li> <li>349 anomalies</li> </ul> </li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ Partitioner based on span_id, here span_id = seconds</code></p> <ul> <li>323 lines + labels(1 if merged lines contain anomalies otherwise 0)</li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ Train dev test split</code></p> <ul> <li> <p>splited result</p> <p>indices_train/dev/test: 181 20 122</p> </li> </ul> <p>Train/Dev/Test Anomalous: 0 0 71</p> <p>Train/Dev/Test Normal: 181 20 51</p> <p><code class="language-plaintext highlighter-rouge">↓ Turn pandas df into LogRecordObject</code></p> <ul> <li><strong>LogRecordObject</strong> test_data, keys: [Timestamp, attributes, span_id, body, labels, _index]</li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ LogVectorizer</code></p> <ul> <li>test_features, features: [‘labels’, ‘input_ids’, ‘token_type_ids’, ‘attention_mask’], num_rows: <strong>122</strong> <ul> <li>for one row:<code class="language-plaintext highlighter-rouge">label: [1] input_ids size: 120 value: [[2, 1378, 584, 5, 1278, 855, 3, 1548, 855, 584, 5, 1278, 1287, 11, 11, 1729, 23, 50, 11, 401, 11, 1565, 11, 1287, 51, 139, 3, 1160, 855, 968, 821, 2087, 3, 576, 864, 454, 2075, 10, 2123, 17, 11, 182, 18, 3, 2082, 2107, 9, 2035, 312, 2126, 3, 1685, 1160, 1339, 3, 1685, 1339, 2119, 3, 2046, 1160, 2101, 3, 1965, 576, 2056, 10, 2027, 2055, 1010, 1964, 1691, 3, 1160, 855, 454, 908, 3, 42, 563, 406, 94, 75, 462, 216, 454, 1419, 206, 1041, 95, 85, 3, 182, 32, 549, 1650, 71, 9, 185, 454, 672, 264, 1693, 1346, 10, 1334, 139, 10, 139, 5, 1333, 139, 5, 393, 5, 408, 428, 1315, 11, 3]] token_type_ids size: 120 value: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] attention_mask size: 120 value: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</code></li> </ul> </li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ NNAnomalyDetector.predict _generate_masked_input</code></p> <ul> <li> <p>mlm_dataset_test [masked language model]</p> <p>Dataset({ features: [‘labels’, ‘input_ids’, ‘token_type_ids’, ‘attention_mask’, ‘indices’], num_rows: <strong>1348</strong> })</p> <ul> <li>for one row:<code class="language-plaintext highlighter-rouge">Labels: [[-100, 1378, 584, -100, 1278, 855, -100, 1548, 855, 584, -100, 1278, 1287, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]] Input_ids size: 120 value: [[2, 4, 4, 5, 4, 4, 3, 4, 4, 4, 5, 4, 4, 11, 11, 1729, 23, 50, 11, 401, 11, 1565, 11, 1287, 51, 139, 3, 1160, 855, 968, 821, 2087, 3, 576, 864, 454, 2075, 10, 2123, 17, 11, 182, 18, 3, 2082, 2107, 9, 2035, 312, 2126, 3, 1685, 1160, 1339, 3, 1685, 1339, 2119, 3, 2046, 1160, 2101, 3, 1965, 576, 2056, 10, 2027, 2055, 1010, 1964, 1691, 3, 1160, 855, 454, 908, 3, 42, 563, 406, 94, 75, 462, 216, 454, 1419, 206, 1041, 95, 85, 3, 182, 32, 549, 1650, 71, 9, 185, 454, 672, 264, 1693, 1346, 10, 1334, 139, 10, 139, 5, 1333, 139, 5, 393, 5, 408, 428, 1315, 11, 3]] token_type_ids size: 120 value: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] attention_mask size: 120 value: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</code></li> <li>what does _generate_masked_input do? <ul> <li>add masks on raw dataset:</li> <li><code class="language-plaintext highlighter-rouge">examples1 = {'input_ids' : [[10,5,7,-1,2]], 'attention_mask' : [[1,1,1,1,1]], 'token_type_ids' : [[0,0,0,0,0]]} indices = [0] output = generate_masked_input(examples1, indices) output {'input_ids': array([[ 4, 5, 7, -1, 2], [10, 4, 7, -1, 2], [10, 5, 4, -1, 2], [10, 5, 7, -1, 4]], dtype=int64), 'attention_mask': array([[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]), 'token_type_ids': array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]), 'labels': array([[ 10, -100, -100, -100, -100], [-100, 5, -100, -100, -100], [-100, -100, 7, -100, -100], [-100, -100, -100, -100, 2]]), 'indices': array([0, 0, 0, 0], dtype=int64)}</code></li> </ul> </li> </ul> </li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ NNAnomalyDetector.predict predict</code></p> <ul> <li> <p>test_results</p> <p>Test_results [‘predictions’, ‘label_ids’, ‘metrics’]</p> <ul> <li>Metrics: [‘test_loss’,’test_runtime’,’test_samples_per_second’,’test_steps_per_second]</li> <li> <p>One shard: [to avoid OOM, the whole mlm_dataset_test is split into 10 shards, and do prediction on each shard]</p> <p>Predictions.shape: (135,120,2220) Label_ids.shape: (135,120) 135*10-2 = 1348</p> </li> <li> <p>All result shape: (1348,120,2220)</p> <p>2220 is the volabulary size</p> <p>120 is the seq length</p> <p>1348 is the # of seqs</p> </li> <li> <p><strong>intepretation</strong><code class="language-plaintext highlighter-rouge">filtered_result = predict_result[5, [10,14,20,25], :] *# filtered_result has a shape of (4,2220)# for each 2220 vector, it shows the prob distribution of words behind this mask# you can get the output probability of real token_ids:* prob1 = predict_result[5,10,4] prob2 = predict_result[5,14,6] prob3 = predict_result[5,20,8] prob4 = predict_result[5,25,11] *# calculate cross entropy loss: -p*log(p)* entropy_i = -prob_i * log(prob_i) *# get a list of losses* entropies = [entropy1, entropy2, entropy3, entropy4, ...] *# calculate top 6 losses and take the mean of them as anomaly score:* anomaly score = mean(top6(entropies)) *# after this process, we can get a anomaly scores of shape (1348,)*</code></p> <p><strong>The Bert output has the same dimension of input, in this case the input is the mlm_dataset_test (1348,120), embed each token_id into 2220 dictionary vector, then it’s (1348,120, 2220), so the output is the same dimension of (1348,120,2220)</strong></p> <p><strong>for each log lines, we only need to calculate the loss function on the masked words, which were specified by a special token type [mask].</strong></p> <p><strong>for example, let’s assume in the masked logline 5, the index [10,14,20,25] are 4 words positions with [mask], and their token_ids are [4, 6, 8, 11]. We fetch those data out:</strong></p> </li> </ul> </li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ anomaly_results.groupby('indices').mean()</code></p> <ul> <li>aggregate the anomaly score of the same index, calculate the mean of them as the final anomaly score of this log line.</li> </ul> <h2 id="38-the-code-modification-for-the-use-of-gpu-acceleration-and-no-partitioning"><strong>3.8 The code modification for the use of GPU acceleration and no partitioning</strong></h2> <ul> <li> <p>in logai\logai\algorithms\nn_model\logbert[train.py](http://train.py/):</p> <p>intend to use GPU if the environment has, not sure if this change is necessary, because I had experience that forgot to change train.py but still trained with GPU.</p> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>

<span class="k">def</span> <span class="nf">_initialize_trainer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">dev_dataset</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">initializing huggingface trainer object for logbert</span><span class="sh">"""</span>
        <span class="n">training_args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="n">model_dirpath</span><span class="p">,</span>
            <span class="n">evaluation_strategy</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">evaluation_strategy</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">num_train_epochs</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">logging_steps</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">per_device_train_batch_size</span><span class="p">,</span>
            <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">per_device_eval_batch_size</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">save_steps</span><span class="p">,</span>
            <span class="n">eval_steps</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">eval_steps</span><span class="p">,</span>
            <span class="n">resume_from_checkpoint</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">resume_from_checkpoint</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">data_collator</span> <span class="o">=</span> <span class="nc">DataCollatorForLanguageModeling</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">mlm_probability</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">mlm_probability</span><span class="p">,</span>
            <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">max_token_len</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1">## modified by huiyu
</span>        <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">():</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dev_dataset</span><span class="p">,</span>
                <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
                    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
                    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dev_dataset</span><span class="p">,</span>
                    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
            <span class="p">)</span>

</code></pre></div></div> <ul> <li>in logai\logai\algorithms\nn_model\logbert[predict.py](http://predict.py/): <ul> <li>I partitioned the log lines in the beginning because in the condition of no partitioning, during the execution of _generate_masked_input, it prompted an error “num_sections must be bigger than 0”, because there were cases that the whole log line contains purely so called special_token_ids.</li> <li>Added code ensures that lines with pure special tokens should return all labels with -100 so that they will not be taken into account when calculating the loss function in the later phase; in simple words, those lines will be neglected.</li> </ul> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_generate_masked_input</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">attention_masks</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">token_type_ids</span><span class="sh">"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="n">sliding_window_diag</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">input_ids</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">sliding_window_diag</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">examples</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">isin</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">special_token_ids</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">sliding_window_diag</span> <span class="o">=</span> <span class="n">sliding_window_diag</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">sliding_window_diag</span> <span class="o">=</span> <span class="n">sliding_window_diag</span><span class="p">[</span>
            <span class="o">~</span><span class="n">np</span><span class="p">.</span><span class="nf">all</span><span class="p">(</span><span class="n">sliding_window_diag</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="c1">## modified by huiyu
</span>        <span class="k">if</span> <span class="n">sliding_window_diag</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">])</span>
            <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">])</span>
            <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">token_type_ids</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="sh">'</span><span class="s">token_type_ids</span><span class="sh">'</span><span class="p">])</span>
            <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">indices</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">index</span><span class="p">]).</span><span class="nf">astype</span><span class="p">(</span>
                <span class="n">np</span><span class="p">.</span><span class="n">int64</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">output</span>
        <span class="c1">##
</span>        <span class="n">num_sections</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">sliding_window_diag</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">mask_ngram</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_sections</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">num_sections</span> <span class="o">=</span> <span class="n">sliding_window_diag</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">sliding_window_diag</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array_split</span><span class="p">(</span><span class="n">sliding_window_diag</span><span class="p">,</span> <span class="n">num_sections</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">diag</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">di</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">sliding_window_diag</span><span class="p">])</span>

        <span class="n">input_rpt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">tile</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="p">(</span><span class="n">diag</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">copy</span><span class="p">(</span><span class="n">input_rpt</span><span class="p">)</span>
        <span class="n">input_ids_masked</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_rpt</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">diag</span><span class="p">)</span> <span class="o">+</span> <span class="n">diag</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">mask_id</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="n">int64</span>
        <span class="p">)</span>
        <span class="n">attention_masks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">tile</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">attention_masks</span><span class="p">),</span> <span class="p">(</span><span class="n">input_ids_masked</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">tile</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">token_type_ids</span><span class="p">),</span> <span class="p">(</span><span class="n">input_ids_masked</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">labels</span><span class="p">[</span>
            <span class="n">input_ids_masked</span> <span class="o">!=</span> <span class="n">self</span><span class="p">.</span><span class="n">mask_id</span>
        <span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>  <span class="c1"># Need masked LM loss only for tokens with mask_id
</span>        <span class="n">examples</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_ids_masked</span>
        <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_masks</span>
        <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">token_type_ids</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">token_type_ids</span>
        <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">indices</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">index</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_ids_masked</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="nf">astype</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="n">int64</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">examples</span>

</code></pre></div></div> <ul> <li> <p>in logai\logai\algorithms\vectorization_algo\logbert.py:</p> <p>This is one crutial change to the logai package. In the following _clean_dataset() method, log lines with pure special tokens will be excluded. The problem is that we don’t know the index of included lines when this function returns.</p> <ul> <li>To get the original indices, we need to return “old indices” from cleandataset() and return again in transform();</li> <li> <p>Also change the receiving params in fit(): cleaned_logrecord, _ = self._clean_dataset(logrecord)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">## modified by Huiyu
</span>  <span class="c1">## return indices from _clean_dataset, and return them in transform()
</span>  <span class="k">def</span> <span class="nf">_clean_dataset</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logrecord</span><span class="p">:</span> <span class="n">LogRecordObject</span><span class="p">):</span>
      <span class="n">special_tokens</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_all_special_tokens</span><span class="p">()</span>
      <span class="n">loglines</span> <span class="o">=</span> <span class="n">logrecord</span><span class="p">.</span><span class="n">body</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LOGLINE_NAME</span><span class="p">]</span>
      <span class="n">loglines_removed_special_tokens</span> <span class="o">=</span> <span class="n">loglines</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span>
          <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">))</span> <span class="o">-</span> <span class="nf">set</span><span class="p">(</span><span class="n">special_tokens</span><span class="p">)).</span><span class="nf">strip</span><span class="p">()</span>
      <span class="p">)</span>
      <span class="n">indices</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">logrecord</span><span class="p">.</span><span class="n">body</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">loglines_removed_special_tokens</span> <span class="o">!=</span> <span class="sh">""</span><span class="p">].</span><span class="n">index</span><span class="p">)</span>
        
      <span class="n">logrecord</span> <span class="o">=</span> <span class="n">logrecord</span><span class="p">.</span><span class="nf">select_by_index</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">logrecord</span><span class="p">,</span> <span class="n">indices</span>
        
  <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logrecord</span><span class="p">:</span> <span class="n">LogRecordObject</span><span class="p">):</span>
      <span class="sh">"""</span><span class="s">Transform method for running vectorizer over logrecord object.
        
      :param logrecord: A log record object containing the dataset
          to be vectorized.
      :return: HuggingFace dataset object.
      </span><span class="sh">"""</span>
      <span class="n">cleaned_logrecord</span><span class="p">,</span> <span class="n">old_indices</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_clean_dataset</span><span class="p">(</span><span class="n">logrecord</span><span class="p">)</span>
      <span class="n">dataset</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_hf_dataset</span><span class="p">(</span><span class="n">cleaned_logrecord</span><span class="p">)</span>
      <span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span>
          <span class="n">self</span><span class="p">.</span><span class="n">_tokenize_function</span><span class="p">,</span>
          <span class="n">batched</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
          <span class="n">num_proc</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">num_proc</span><span class="p">,</span>
          <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LOGLINE_NAME</span><span class="p">],</span>
      <span class="p">)</span>
      <span class="k">return</span> <span class="n">tokenized_dataset</span><span class="p">,</span> <span class="n">old_indices</span>
      <span class="c1">##
</span>        
  <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logrecord</span><span class="p">:</span> <span class="n">LogRecordObject</span><span class="p">):</span>
          <span class="sh">"""</span><span class="s">Fit method for training vectorizer for logbert.
        
          :param logrecord: A log record object containing the training
              dataset over which vectorizer is trained.
          </span><span class="sh">"""</span>
        
          <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">tokenizer_dirpath</span><span class="p">):</span>
              <span class="k">return</span>
  				<span class="c1">#also change here
</span>          <span class="n">cleaned_logrecord</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_clean_dataset</span><span class="p">(</span><span class="n">logrecord</span><span class="p">)</span>
          <span class="n">dataset</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_hf_dataset</span><span class="p">(</span><span class="n">cleaned_logrecord</span><span class="p">)</span>
        
          <span class="k">def</span> <span class="nf">batch_iterator</span><span class="p">():</span>
              <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">train_batch_size</span><span class="p">):</span>
                  <span class="k">yield</span> <span class="n">dataset</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">train_batch_size</span><span class="p">][</span>
                      <span class="n">constants</span><span class="p">.</span><span class="n">LOGLINE_NAME</span>
                  <span class="p">]</span>
        
          <span class="n">trainer</span> <span class="o">=</span> <span class="n">trainers</span><span class="p">.</span><span class="nc">WordPieceTrainer</span><span class="p">(</span>
              <span class="n">vocab_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">max_vocab_size</span><span class="p">,</span> <span class="n">special_tokens</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">special_tokens</span>
          <span class="p">)</span>
        
          <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">train_from_iterator</span><span class="p">(</span><span class="nf">batch_iterator</span><span class="p">(),</span> <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>
        
          <span class="n">cls_token_id</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">token_to_id</span><span class="p">(</span><span class="sh">"</span><span class="s">[CLS]</span><span class="sh">"</span><span class="p">)</span>
          <span class="n">sep_token_id</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">token_to_id</span><span class="p">(</span><span class="sh">"</span><span class="s">[SEP]</span><span class="sh">"</span><span class="p">)</span>
        
          <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">post_processor</span> <span class="o">=</span> <span class="n">processors</span><span class="p">.</span><span class="nc">TemplateProcessing</span><span class="p">(</span>
              <span class="n">single</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">[CLS]:0 $A:0 [SEP]:0</span><span class="sh">"</span><span class="p">,</span>
              <span class="n">pair</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1</span><span class="sh">"</span><span class="p">,</span>
              <span class="n">special_tokens</span><span class="o">=</span><span class="p">[</span>
                  <span class="p">(</span><span class="sh">"</span><span class="s">[CLS]</span><span class="sh">"</span><span class="p">,</span> <span class="n">cls_token_id</span><span class="p">),</span>
                  <span class="p">(</span><span class="sh">"</span><span class="s">[SEP]</span><span class="sh">"</span><span class="p">,</span> <span class="n">sep_token_id</span><span class="p">),</span>
              <span class="p">],</span>
          <span class="p">)</span>
        
          <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoders</span><span class="p">.</span><span class="nc">WordPiece</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="sh">"</span><span class="s">##</span><span class="sh">"</span><span class="p">)</span>
          <span class="n">new_tokenizer</span> <span class="o">=</span> <span class="nc">BertTokenizerFast</span><span class="p">(</span><span class="n">tokenizer_object</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">)</span>
        
          <span class="n">new_tokenizer</span><span class="p">.</span><span class="nf">save_pretrained</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">tokenizer_dirpath</span><span class="p">)</span>
          <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">new_tokenizer</span>
</code></pre></div> </div> </li> </ul> </li> </ul>]]></content><author><name>Huiyu Chu</name></author><category term="Computer Science"/><category term="bert"/><summary type="html"><![CDATA[1. General Knowledge about Bert]]></summary></entry><entry><title type="html">Git manual</title><link href="https://chuhuiyu.github.io/blog/2020/GIT/" rel="alternate" type="text/html" title="Git manual"/><published>2020-01-11T02:14:17+00:00</published><updated>2020-01-11T02:14:17+00:00</updated><id>https://chuhuiyu.github.io/blog/2020/GIT</id><content type="html" xml:base="https://chuhuiyu.github.io/blog/2020/GIT/"><![CDATA[<h1 id="git">GIT</h1> <p><a href="https://www.liaoxuefeng.com/wiki/896043488029600">Git教程 - 廖雪峰的官方网站 (liaoxuefeng.com)</a></p> <h1 id="basics">Basics</h1> <p>创建repo：</p> <p>git init</p> <p>添加文件到repo：</p> <p>git add xx</p> <p>提交到repo：</p> <p>git commit -m “xx”</p> <p>查看repo状态：</p> <p>git status</p> <p>查看被修改文件的具体修改内容：</p> <p>git diff xx.xx</p> <h1 id="version-control">version control</h1> <p>git log —pretty=oneline查看以往版本</p> <p>git reset —hard HEAD^ / git reset —hard 1094a</p> <p>git reflog记录每一次命令</p> <p>删除：</p> <p><code class="language-plaintext highlighter-rouge">git rm test.txt</code></p> <p><code class="language-plaintext highlighter-rouge">git **commit** -m "remove test.txt"</code></p> <p>在Git中，用<code class="language-plaintext highlighter-rouge">HEAD</code>表示当前版本，上一个版本就是<code class="language-plaintext highlighter-rouge">HEAD^</code>，上上一个版本就是<code class="language-plaintext highlighter-rouge">HEAD^^</code>，当然往上100个版本写100个<code class="language-plaintext highlighter-rouge">^</code>比较容易数不过来，所以写成<code class="language-plaintext highlighter-rouge">HEAD~100</code></p> <h2 id="撤销修改">撤销修改</h2> <p>命令<code class="language-plaintext highlighter-rouge">git checkout -- readme.txt</code>意思就是，把<code class="language-plaintext highlighter-rouge">readme.txt</code>文件在工作区的修改全部撤销，这里有两种情况：</p> <p>一种是<code class="language-plaintext highlighter-rouge">readme.txt</code>自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；</p> <p>一种是<code class="language-plaintext highlighter-rouge">readme.txt</code>已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。</p> <p>总之，就是让这个文件回到最近一次<code class="language-plaintext highlighter-rouge">git commit</code>或<code class="language-plaintext highlighter-rouge">git add</code>时的状态。</p> <p>用命令<code class="language-plaintext highlighter-rouge">git reset HEAD &lt;file&gt;</code> 可以把暂存区的修改撤销掉（unstage），重新放回工作区</p> <p>场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令<code class="language-plaintext highlighter-rouge">git checkout -- file</code>。</p> <p>场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令<code class="language-plaintext highlighter-rouge">git reset HEAD &lt;file&gt;</code>，就回到了场景1，第二步按场景1操作。</p> <p>场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考<a href="https://www.liaoxuefeng.com/wiki/896043488029600/897013573512192">版本回退</a>一节，不过前提是没有推送到远程库。</p> <h2 id="标签">标签</h2> <p>命令<code class="language-plaintext highlighter-rouge">git tag</code>可以查看所有标签。</p> <p><code class="language-plaintext highlighter-rouge">git tag v1.0</code> 打在commit上</p> <p><code class="language-plaintext highlighter-rouge">git tag v0.9 f52c633</code> 打在历史某commit上</p> <p>删除标签：<code class="language-plaintext highlighter-rouge">git tag -d v0.1</code> [<a href="https://www.liaoxuefeng.com/wiki/896043488029600/902335479936480">操作标签 - 廖雪峰的官方网站 (liaoxuefeng.com)</a>]</p> <p>带说明的标签： <code class="language-plaintext highlighter-rouge">git tag -a v0.1 -m "version 0.1 released" 1094adb</code></p> <p>用命令<code class="language-plaintext highlighter-rouge">git show &lt;tagname&gt;</code>可以看到说明文字</p> <h1 id="分支管理">分支管理</h1> <p>创建+切换分支：<code class="language-plaintext highlighter-rouge">git checkout -b &lt;name&gt;</code> 或者<code class="language-plaintext highlighter-rouge">git switch -c &lt;name&gt;</code></p> <p><code class="language-plaintext highlighter-rouge">git checkout -b dev</code> 创建分支dev，-b表示创建并切换到该分支，相当于：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git branch dev
$ git checkout dev
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">git checkout master</code> 切换回master分支</p> <p><code class="language-plaintext highlighter-rouge">git switch -c dev</code> 建议用switch来切换，避免与撤销混淆</p> <p><code class="language-plaintext highlighter-rouge">git branch</code> 查看当前分支</p> <p><code class="language-plaintext highlighter-rouge">git merge dev</code> 把<code class="language-plaintext highlighter-rouge">dev</code>分支的工作成果合并到<code class="language-plaintext highlighter-rouge">master</code>分支上</p> <p>合并完成后，就可以放心地删除<code class="language-plaintext highlighter-rouge">dev</code>分支了：</p> <p><code class="language-plaintext highlighter-rouge">git branch -d dev</code></p> <p>当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。</p> <p>解决冲突就是把Git合并失败的文件手动编辑为我们希望的内容，再提交。</p> <p>用<code class="language-plaintext highlighter-rouge">git log --graph</code>命令可以看到分支合并图。<code class="language-plaintext highlighter-rouge">git log --graph --pretty=oneline --abbrev-commit</code></p> <p><code class="language-plaintext highlighter-rouge">git merge --no-ff -m "merge with no-ff" dev</code> 禁用<code class="language-plaintext highlighter-rouge">Fast forward</code></p> <p><img src="/assets/img/git/Untitled.png" alt="Untitled"/></p> <p>不使用<code class="language-plaintext highlighter-rouge">Fast forward</code>模式，merge后就像这样：</p> <p><img src="/assets/img/git/Untitled1.png" alt="Untitled"/></p> <p>首先，<code class="language-plaintext highlighter-rouge">master</code>分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活；</p> <p>那在哪干活呢？干活都在<code class="language-plaintext highlighter-rouge">dev</code>分支上，也就是说，<code class="language-plaintext highlighter-rouge">dev</code>分支是不稳定的，到某个时候，比如1.0版本发布时，再把<code class="language-plaintext highlighter-rouge">dev</code>分支合并到<code class="language-plaintext highlighter-rouge">master</code>上，在<code class="language-plaintext highlighter-rouge">master</code>分支发布1.0版本；</p> <p>你和你的小伙伴们每个人都在<code class="language-plaintext highlighter-rouge">dev</code>分支上干活，每个人都有自己的分支，时不时地往<code class="language-plaintext highlighter-rouge">dev</code>分支上合并就可以了。</p> <p>团队合作的分支看起来就像这样：</p> <p><img src="/assets/img/git/Untitled2.png" alt="Untitled"/></p> <p>BUG分支：<a href="https://www.liaoxuefeng.com/wiki/896043488029600/900388704535136">Bug分支 - 廖雪峰的官方网站 (liaoxuefeng.com)</a></p> <p>FEATURE分支：<a href="https://www.liaoxuefeng.com/wiki/896043488029600/900394246995648">Feature分支 - 廖雪峰的官方网站 (liaoxuefeng.com)</a></p> <h1 id="远程仓库github">远程仓库（GITHUB）</h1> <p>要查看远程库的信息，用<code class="language-plaintext highlighter-rouge">git remote</code></p> <p>用<code class="language-plaintext highlighter-rouge">git remote -v</code>显示更详细的信息</p> <p><code class="language-plaintext highlighter-rouge">git push origin master</code> 推送分支</p> <p>如果要推送其他分支，比如<code class="language-plaintext highlighter-rouge">dev</code>，就改成：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git push origin dev
</code></pre></div></div> <p>设置<code class="language-plaintext highlighter-rouge">dev</code>和<code class="language-plaintext highlighter-rouge">origin/dev</code>的链接：<code class="language-plaintext highlighter-rouge">git branch *--set-upstream-to=origin/dev dev*</code></p> <p><code class="language-plaintext highlighter-rouge">Branch 'dev' **set** up **to** track remote branch 'dev' **from** 'origin'.</code></p> <p>因此，多人协作的工作模式通常是这样：</p> <ol> <li>首先，可以试图用<code class="language-plaintext highlighter-rouge">git push origin &lt;branch-name&gt;</code>推送自己的修改；</li> <li>如果推送失败，则因为远程分支比你的本地更新，需要先用<code class="language-plaintext highlighter-rouge">git pull</code>试图合并；</li> <li>如果合并有冲突，则解决冲突，并在本地提交；</li> <li>没有冲突或者解决掉冲突后，再用<code class="language-plaintext highlighter-rouge">git push origin &lt;branch-name&gt;</code>推送就能成功！</li> </ol> <p>如果<code class="language-plaintext highlighter-rouge">git pull</code>提示<code class="language-plaintext highlighter-rouge">no tracking information</code>，则说明本地分支和远程分支的链接关系没有创建，用命令<code class="language-plaintext highlighter-rouge">git branch --set-upstream-to &lt;branch-name&gt; origin/&lt;branch-name&gt;</code>。</p> <p>这就是多人协作的工作模式，一旦熟悉了，就非常简单。</p> <h1 id="git结构">Git结构</h1> <p><img src="/assets/img/git/Untitled3.png" alt="Untitled"/></p> <ul> <li>工作区</li> <li>暂存区(stage/index)</li> <li>指向master的指针HEAD</li> </ul>]]></content><author><name></name></author><category term="Computer Science"/><category term="git"/><summary type="html"><![CDATA[GIT]]></summary></entry><entry><title type="html">Information Theory -4</title><link href="https://chuhuiyu.github.io/blog/2019/Information-Theory-4/" rel="alternate" type="text/html" title="Information Theory -4"/><published>2019-05-30T02:14:17+00:00</published><updated>2019-05-30T02:14:17+00:00</updated><id>https://chuhuiyu.github.io/blog/2019/Information-Theory-4</id><content type="html" xml:base="https://chuhuiyu.github.io/blog/2019/Information-Theory-4/"><![CDATA[<h1 id="抗干扰二元编码原理及方法">抗干扰二元编码原理及方法</h1> <p>[TOC]</p> <h2 id="41-抗干扰编码的基本原理">4.1 抗干扰编码的基本原理</h2> <h3 id="411-编码和纠错能力的关系">4.1.1 编码和纠错能力的关系</h3> <ol> <li> <p>只检测e个错：最小码距：$d_{min} &gt;=e+1$</p> <p>助记：假设就检测一个错，而最小码距是1，那根本无法检测错误，因此至少e+1</p> <p>解释:</p> <div class="col-sm mt-3 mt-md-0"> </div> </li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Information-Theory-4/001-480.webp 480w,/assets/img/Information-Theory-4/001-800.webp 800w,/assets/img/Information-Theory-4/001-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Information-Theory-4/001.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>&lt;/div&gt;</p> <p>设一码组A位于O点，另一码组B与A最小码距为d0。当A码组发生e个误码时，可以认为A的位置将移动到以O为圆心、以e为半径的圆上，但其位置不会超出此圆。只要e比d0小1，发生个错码后错成的码组不可能变成另一任何许用码组，即有d&gt;=e+1。</p> <ol> <li>纠正t个错:$d_{min} &gt;= 2t +1$</li> </ol> <p>助记：我想纠正t个错，那码距如果是2t，将会纠错困难，信宿收到了A，字母表B和C距A都是t，那把B译成C还是A？那么要让$d_{min}$ 再多一位，那么B和C肯定有一个距A更小，则将A译成它。</p> <p>解释:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Information-Theory-4/002-480.webp 480w,/assets/img/Information-Theory-4/002-800.webp 800w,/assets/img/Information-Theory-4/002-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Information-Theory-4/002.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>例如：</p> <p>$\sum : B,C \; $</p> <p>B：1111 C：0000 $d_{min} = 4$</p> <p>A：1100 无法纠错</p> <p>码距+1： B：11111 C：00000</p> <p>A: 11100 / 11000 均能纠错</p> <ol> <li>纠正t个错，检测e个错：$d_{min} &gt;= t+e+1 (e&gt;t) $</li> </ol> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Information-Theory-4/003-480.webp 480w,/assets/img/Information-Theory-4/003-800.webp 800w,/assets/img/Information-Theory-4/003-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Information-Theory-4/003.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>在解释此式之前，先来说明什么是“纠正个错码，同时又检测e个错码” （简称纠检结合）。在某些情况下，要求对于出现较频繁但错码数很少的码组按前向纠错方式工作，以</p> <p>节省反馈重发时间,同时又希望对一些错码数较多的码组,在超过该码的纠错能力时,能自动按检错重发方式工作,以降低系统的总误码率。这种工作方式就是“纠检结合”</p> <p>在上述“纠检结合”系统中，差错控制设备按照接收码组与许用码组的距离自动改变工作方式。若接收码组与某一许用码组间的距离在纠错能力t的范围内，则将按纠错方式工作，否则按检错方式工作。若设码组的检错能力为e,则当码组存在e个错码时,该码组与任一许用码组B的距离至少应有t+1,否则将进入许用码组B的纠错能力范围内，而被错纠为B，这就要求最小码距应满足图(c)。</p> <h3 id="412-抗干扰编码的基本原理">4.1.2 抗干扰编码的基本原理</h3> <p>山农编码定理 -&gt;</p> <p>码组足够长时，存在一种编码方法，使增加的监督码元与原来的信息码元相比趋于任意小，效率</p> <p>$\displaystyle\eta = \frac{R}{C}\to 1$</p> <p>代数编码：监督码由信息码按一定算法给出。 分为<strong>分组码</strong>和<strong>卷积码</strong>。</p> <ul> <li>分组码</li> </ul> <ol> <li> <p>k信息+r监督= n -&gt; (n,k)码</p> </li> <li> <p>$\displaystyle\eta = \frac{k}{n}$</p> </li> <li> <p>系统码： 监督位都在后面</p> </li> </ol> <ul> <li>卷积码</li> </ul> <ol> <li>k个信息码输入到一个时序逻辑电路，输出与前m组输入的k有关：</li> </ol> <p>$m’k+k = (m’+1)k = mk$</p> <ol> <li>m -&gt; 编码约束度</li> </ol> <p>$n_总$ = m * n = (m’+1)* n</p> <p>$\displaystyle\eta = \frac{k}{n}$</p> <h2 id="42-构造检错码">4.2 构造检错码</h2> <h3 id="421-奇偶校验码">4.2.1 奇偶校验码</h3> <ol> <li> <p>(n,n-1)码</p> <p>效率 $\displaystyle\eta = \frac{n-1}{n} $</p> </li> <li> <p>漏检概率</p> <p>奇偶校验码不能发现偶数错误： （$p_e : 误码率$)</p> <p>n为偶数：</p> <p>$p = \displaystyle\sum\limits_{i=1}^{n/2} C_{n}^{2i} p_{e}^{2i} (1-p_e)^{n-2i} \to p\approx\displaystyle\sum\limits_{x=1}^n C_n^xp_e^x 保留第一项得 p = C_n^2p_e^2 $</p> <p>n为奇数：</p> <p>$p= \displaystyle\sum\limits_{i=1}^{(n-1)/2} C_{n}^{2i} p_{e}^{2i} (1-p_e)^{n-2i}$</p> <p>$由于p_e «1，上面近似为 p \approx C_n^2p_e^2$</p> </li> <li> <p>例题： 4.4 (8,7)奇偶校验码的漏检概率和编码效率( $p_e = 10^{-4}$)</p> <p>​ 7/8 ; $C_8^2 p_e^2$</p> </li> </ol> <h3 id="422-定比码">4.2.2 定比码</h3> <p>——又叫等重码，1的个数为码的重量</p> <ol> <li></li> </ol> <p>53定比-&gt;与10个十进制数字对应，4个10进制数字代表一个汉字，于是可用于汉字编码</p> <p>​ $C_5^3 = 10个许用码字，22个禁用$</p> <p>73定比-&gt; 对英文字母和键盘操作编码 $C_7^3=35个许用码字，2^7-C_7^3 = 93个禁用码字$</p> <ol> <li></li> </ol> <p>效率 $\displaystyle\eta = \frac{R}{C} ,R为每个码元的平均信息量，C为每个符号最大信息量$</p> <p>53定比，许用10码字，若等概率分布，每个码字平均信息量= lb($C_{5}^3$),每个码元的平均信息量则为lb(*)/5 = 0.66 bit/signal</p> <p>二元信源每个符号最大信息量为1bit/signal</p> <p>所以 $\eta = 66 \%$</p> <p>73类似</p> <ol> <li>ARQ - Automatic Request for Repeat 检测到错误重发</li> </ol> <h2 id="43-构造纠错码">4.3 构造纠错码</h2> <h3 id="431-简单重复码">4.3.1 简单重复码</h3> <p>发 001100 -&gt; 三重重复码 000，000，111，111，000，000</p> <p>n重重复码 : 效率 = 1/n</p> <h3 id="432-汉明码---纠正1位错误">4.3.2 汉明码 - 纠正1位错误</h3> <ol> <li>$2^r = n+1 \to 狭义汉明码 ，2^r &gt;n+1 广义汉明码$</li> <li>监督矩阵[H]，确定信息码元和监督码元的关系</li> <li>生成矩阵[G],信息码A右乘G即得系统码B 掌握H、G的互换</li> <li>错误接受概率(实际误码率) $p = 1- [ (1-p_e)^n + C_n^1 p_e (1-p_e)^{n-1}]$</li> </ol> <p>$p_e = 10^{-4} 时 p_{(7,4)} \approx 4.2* 10^{-7}$</p> <ol> <li>$\eta = k/n =4/7 \approx 57\%$</li> </ol> <h3 id="433-crc-循环冗余校验码">4.3.3 CRC 循环冗余校验码</h3> <p>​ —— Cyclic Redundancy Check</p> <ol> <li> <p>循环码是分组码 (n,k) 这里只讨论线性循环码</p> </li> <li> <p>码字 &lt;=&gt; 多项式 左乘$x^c$模($x_n+1$) &lt;=&gt; 左移c位 涉及模二运算</p> </li> <li> <p>生成多项式-&gt;生成矩阵-&gt;解决循环码编码</p> <p>定理： (n,k)循环码生成多项式g(x) 是 $x^n -1 的r次(n-k)因式$</p> </li> <li> <p>根据生成多项式$g(x) = x^3+x+1$ (1011)通过两种方法求循环码的码字表：</p> <ul> <li> <p>求生成矩阵[G]</p> <p>[1011000,</p> <p>0101100,</p> <p>0010110,</p> <p>0001011]</p> <p>信息码 A(1:k) * G(k,n) -&gt; 非系统码 B(1:n)</p> </li> <li> <p>直接利用g(x)：</p> <p>信息码A(x)</p> <p>$x^{n-k}<em>A(x) = y</em>g(x) + r(x)$</p> <p>B(x) = A(x) + r(x)</p> </li> </ul> </li> <li> <p>根据一个特定循环码字可求出所有校验子</p> </li> </ol> <p>求传输错误后的B(x)’ = B(x) + e(x)</p> <p>把B(x)’ mod $g(x)$ , e(x)即为校验子</p>]]></content><author><name></name></author><category term="Computer Science"/><category term="Information Theory"/><summary type="html"><![CDATA[抗干扰二元编码原理及方法]]></summary></entry><entry><title type="html">Intro2-Computational-Neuroscience-w2</title><link href="https://chuhuiyu.github.io/blog/2019/Intro2-Computer-Neuronscience-w2/" rel="alternate" type="text/html" title="Intro2-Computational-Neuroscience-w2"/><published>2019-05-11T21:57:40+00:00</published><updated>2019-05-11T21:57:40+00:00</updated><id>https://chuhuiyu.github.io/blog/2019/Intro2-Computer-Neuronscience-w2</id><content type="html" xml:base="https://chuhuiyu.github.io/blog/2019/Intro2-Computer-Neuronscience-w2/"><![CDATA[<p>[TOC]</p> <h1 id="neural-code">Neural Code</h1> <p>课程的第一个部分，由于神经科学在理解大脑处理感官信息方面比较成熟，因此将从这一方面入手。</p> <ul> <li>technique for recording from the brain(fMRA…)</li> <li>tools discovering how brain represent information</li> <li>model express our understanding of this representation</li> <li>some methods for inferring what the brain is doing based on its activity(in w3)</li> <li>using <strong>information theory</strong> to quantify neural representation(in w4)</li> <li>biophysical basis of how the brain process inputs and performs complex computations(in w5)</li> </ul> <h2 id="recording">Recording</h2> <p><strong>outside the cell:</strong></p> <ul> <li>fMRI</li> <li>EEG ——electroencephalography <ul> <li>faster response</li> </ul> </li> </ul> <p>both of them have the same shortage: can not recode one single neuron’s activity but an average of millons’</p> <p>some ways to read single neuron:</p> <ul> <li>electrode arrays</li> <li>calcium imaging 钙离子荧光染色？神经冲动时钙离子内流，荧光强度代表活动强度</li> </ul> <p><strong>looking inside single cells:</strong></p> <ul> <li> <p>patch electrodes</p> <p>direct contact with inside of the cell</p> </li> </ul> <h2 id="what-is-the-neural-code">what is the neural code？</h2> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/001-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/001-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/001-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/001.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <ul> <li>cells in retina transfer the light signals to the electrical signals</li> </ul> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/002-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/002-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/002-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/002.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>[input]photoreceptors(rods and columns) -&gt;successive layers of cells-&gt;[output]retinal ganglion cells-&gt;optic track(视神经束)-&gt;rest of the brain</p> <p>一个实验：</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/010-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/010-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/010-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/010.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>将视网膜神经节细胞用营养液养好，下面铺着记录每个细胞spike与否的electrode array，然后给他们放电影看:D</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/011-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/011-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/011-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/011.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>并且放很多遍，每遍都把该细胞兴奋的时间点标记出来，综合到上面一张图里，发现同一细胞兴奋点还真是差不多。。。像鱼吐泡泡一样。。。</p> <p>然后把所有细胞的图绘制如下：</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/012-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/012-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/012-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/012.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>发现不同细胞都在对电影片段不同的细节进行编码（encoding)，传送到大脑更高级的部位里。每个细胞都像是一个小电脑在高速编程……把外界信息处理成大脑可以理解的电信号。amazing.</p> <ul> <li> <table> <tbody> <tr> <td>Encoding: P(response</td> <td>stimulus)</td> </tr> </tbody> </table> <p>how does stimulus create a pattern of responses?</p> </li> <li> <table> <tbody> <tr> <td>Decoding: P(stimulus</td> <td>response)</td> </tr> </tbody> </table> <p>what do these response tell us about the stimulus?</p> </li> <li> <p>用密码学来解释: 大脑接收到的外界的刺激是密文，大脑作出的反应是明文。</p> <p>从刺激预测反应是编码，从反应逆向刺激是译码</p> </li> </ul> <p>大脑对刺激反应的复杂度：</p> <p>Geometric to semantic :从几何的到有语义的</p> <p>interconnect: retina/LGN receives a massive amount of feedback from all these areas</p> <p>​ expectation: <strong>what you think you’re looking at can shape what you actually see.</strong>(康德的认识论！)</p> <p>​ (top-down effects)(semantic expectations)</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/003-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/003-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/003-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/003.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/004-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/004-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/004-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/004.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="coding-model">coding model</h2> <h3 id="linear-filtering">linear filtering</h3> <h4 id="basic-coding-model-temporal-filtering-时间滤镜">basic coding model: temporal filtering-时间滤镜</h4> <table> <tbody> <tr> <td>$ P(response</td> <td>stimulus) $</td> </tr> </tbody> </table> <p>response: a single spike produced by a chosen neuron</p> <p>$ r(t) $ : the probability seeing a spike at a certain time(firing rate)</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/005-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/005-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/005-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/005.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <ol> <li>$ r(t) = {\phi} \,s(t)$ or $ r(t) = {\phi}\, s(t-{\tau})$</li> <li>$ r(t) = \displaystyle\sum\limits_{k=0}^n\; s_{t-k}\, f_k$ or integral form: $ r(t) = \int_{-\infty}^t\, d\tau \, s(t-\tau) \, f(\tau)$ EG1： f(t) = 1/T EG2： f(t) = $ e^{t} $</li> </ol> <h4 id="basic-coding-model-spatial-filtering-空间滤镜">basic coding model: spatial filtering-空间滤镜</h4> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/006-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/006-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/006-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/006.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>很容易推出对于r(t)描述的空间模型：</p> <p>​ $ r(t) = \sum_{x’=-n,y’=-n}^{x’=n,y’=n}\, s_{x-x’,y-y’}\, f_{x’,y’}$</p> <p>or r(t) = $ \int_{-\infty}^{\infty}\,dx’dy’s(x-x’,y-y’)f_{x’,y’} $</p> <h4 id="basic-coding-model-spatiotemporal-filtering--时空滤镜">basic coding model: spatiotemporal filtering -时空滤镜</h4> <p>$ r_{x,y}(t) = \displaystyle\int!\int!\int dx’dy’d\tau \, f(x’,y’,\tau) s(x-x’,y-y’,t-\tau)$</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/007-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/007-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/007-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/007.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h3 id="standardized-linear-filtering">Standardized linear filtering</h3> <p>Linear filter &amp; nonlinearity :$ r_{x,y}(t) = g\left(\int!\int!\int dx’dy’d\tau \, f(x’,y’,\tau) s(x-x’,y-y’,t-\tau)\right)$</p> <h3 id="conclusion-of-basic-coding-model">Conclusion of basic coding model</h3> <ol> <li> <p>r(t)肯定是一个跟s(t)有关的函数$r(t) = \phi s(t)$</p> </li> <li> <p>若假设刺激与空间位置无关，只与时间有关，即当前s(current)与前 T s的s(t)有关，并且是这些值的线性和，权重服从函数f(t)(比如$f(t) = e^{-t}$),那么r(t)就是s(t)与f(t)的卷积：</p> <p>$r(t) = \int_{-\infty}^t s(\tau)f(t-\tau)d\tau $ 离散的即：s(0)<em>f(t)+s(1)</em>f(t-1)+s(2)<em>f(t-2)+…s(t)</em>f(0)</p> </li> <li> <p>若假设刺激与时间无关，只与空间位置有关，即与感受野内的刺激有关，并且把感受野内的刺激作一个线性组合，权重或者过滤函数为f(x,y)，那么r(x,y)也同样是s(x,y)与f(x,y)的卷积：</p> <p>$r(x,y) = \int_{-\infty}^x\int_{-\infty}^ydx’dy’\, s(x’,y’)f(x-x’,y-y’) $</p> <p>这个像极了图象处理中的卷积，f即为卷积核。</p> </li> </ol> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/009-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/009-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/009-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/009.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>On-Feature 的 retinal ganglion cells 的 f(x,y)，表示当中心的像素是亮点时，f(0,0)*s(0,0)会是个很大的正数，提升了其r(t)即产生刺激的概率；当周围的像素是暗点时，f和s相乘会是一个绝对值比较小的负数，也相当于提升了r(t)，否则，当周围也是亮点，由于该点的f(x,y)是负值，那么会降低细胞兴奋的概率。</p> <ol> <li> <p>最后我们将时空综合起来，得到一个相对合理的模型，同时考虑了时间和空间对r(t)的影响,并且加入非线性的g(x)使概率控制在合理的范围内(0-1)，相当于对其标准化。</p> <p>$ r_{x,y}(t) = g\left(\int!\int!\int dx’dy’d\tau \, f(x’,y’,\tau) s(x-x’,y-y’,t-\tau)\right)$</p> </li> </ol> <h2 id="feature-selection">Feature Selection</h2> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w2/008-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w2/008-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w2/008-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w2/008.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>现在有一个问题：每一个样本点的数据量太大，我们需要把多余的，相关性强的数据整合成精简的数据</p> <table> <tbody> <tr> <td>即用s1来代表整个stimulus: P(response</td> <td>stimulus) -&gt; P(response</td> <td>s1)</td> </tr> </tbody> </table> <ul> <li>Gaussian white noise</li> </ul> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vacabulary list:
<span class="p">  -</span> calcium n. 钙
<span class="p">  -</span> florescent / flourescent a. 荧光的
<span class="p">  -</span> florescent property 荧光物质
<span class="p">  -</span> clamp 夹具 a device holds two things firmly together
<span class="p">  -</span> integral 积分的
<span class="p">  -</span> map...onto  map the filtered stimulus onto the firing rate.
  
  
</code></pre></div></div>]]></content><author><name></name></author><category term="Computational Neuroscience"/><category term="Computational Neuroscience"/><summary type="html"><![CDATA[[TOC]]]></summary></entry><entry><title type="html">Intro2-Computational-Neuronscience-w1</title><link href="https://chuhuiyu.github.io/blog/2019/Intro2-Computer-Neuronscience-w1/" rel="alternate" type="text/html" title="Intro2-Computational-Neuronscience-w1"/><published>2019-05-11T16:20:40+00:00</published><updated>2019-05-11T16:20:40+00:00</updated><id>https://chuhuiyu.github.io/blog/2019/Intro2-Computer-Neuronscience-w1</id><content type="html" xml:base="https://chuhuiyu.github.io/blog/2019/Intro2-Computer-Neuronscience-w1/"><![CDATA[<p>[TOC]</p> <h2 id="1-使用python作科学计算scientific-python">1. 使用Python作科学计算(scientific python)</h2> <ul> <li>在scripts前习惯添加如下代码 :</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</code></pre></div></div> <ul> <li>使用 pickle module 读取数据：</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pickle</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">stim</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]),</span> <span class="sh">'</span><span class="s">response</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">])}</span>

<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">my_data.pickle</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">f</span><span class="p">)</span>
    
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">my_data.pickle</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">rb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
	<span class="n">new_data</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div> <h2 id="2-models-used-in-cn">2. Models used in CN</h2> <h3 id="models">Models</h3> <ul> <li>Desciptive Models—— what nervous system do</li> <li>Mechanistic Models——how they function</li> <li>Interpretive Models——why they operate in particular ways</li> </ul> <h3 id="receptive-fieldsexperiment">Receptive Fields.Experiment</h3> <p>Example to explain: ——Receptive Fields</p> <p>​ Hubel and Wiesel, c. 1965</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w1/001-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w1/001-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w1/001-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w1/001.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>​ showed that the cat’s cell responded robustly when the bar of light oriented at 45°</p> <p>​ 感受野，感受器受刺激兴奋时，通过感受器官中的向心神经元将神经冲动（各种感觉信息）传到上位中枢，一个神经元所反应（支配）的刺激区域就叫做神经元的感受野（receptive field）【受纳野】。</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w1/002-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w1/002-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w1/002-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w1/002.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h3 id="receptive-fieldsmodels">Receptive Fields.Models</h3> <ul> <li> <p>Desription</p> <ol> <li>Retina 视网膜</li> </ol> <p>layer of tissue back of your eyes(retinal ganglion cells[视网膜神经节细胞] there)</p> <ol> <li> <p>Lateral Geniculate Nucleus(LGN)[外侧膝状体]</p> </li> <li> <p>the Primary Visual Cortex(V1)[初级视皮层]</p> <p>意即通过实验发现视网膜和V1处的细胞有不同的感受野，这是一种<strong>科学发现</strong>,发现其<strong>形式因</strong></p> </li> </ol> </li> </ul> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w1/004-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w1/004-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w1/004-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w1/004.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w1/005-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w1/005-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w1/005-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w1/005.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <ul> <li>Machanical</li> </ul> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w1/006-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w1/006-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w1/006-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w1/006.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>解剖学(anatomy)发现众多的LGN细胞连接到独立的V1细胞，Hubel&amp;Wiesel则推测V1 cell感受野的变形是由于不同LGN细胞的前馈输入叠加。(feed-forward input)</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w1/008-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w1/008-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w1/008-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w1/008.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>这种模型提供了一种<strong>科学解释</strong>，解释其<strong>动力因</strong></p> <ul> <li>Interpretive Model</li> </ul> <p>为什么V1细胞要长成这个样子？这种interpretive model解释了其<strong>目的因</strong></p> <p>进化论的角度：为了表达客观世界图象更加的真实、更加有效</p> <p>（represent images as faithfully and as efficiently as possible)</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w1/009-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w1/009-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w1/009-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w1/009.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>验证模型的正确性：</p> <p>建模：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* 输入：自然图象
* I^ = (自己构造的RFi)*wi
* 将I^ 与输入的 I 对比，比较二者灰度值的差异
* 找到最有效率、最优的RFi
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Intro2-Computer-Neuroscience-w1/010-480.webp 480w,/assets/img/Intro2-Computer-Neuroscience-w1/010-800.webp 800w,/assets/img/Intro2-Computer-Neuroscience-w1/010-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Intro2-Computer-Neuroscience-w1/010.png" class="img-fluid z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="3-conclusion">3. Conclusion</h2> <p>亚里士多德针对认识论提出了“四因说”：每个对象都有其“形式因”，“质料因”，“动力因”，“目的因”</p> <p>CN的三个模型，DESP研究形式因和质料因，MACHA研究动力因，INTERP研究目的因.</p> <p>重要的还是对自己的模型进行验证:)</p>]]></content><author><name></name></author><category term="Computational Neuroscience"/><category term="Computational Neuroscience"/><summary type="html"><![CDATA[[TOC]]]></summary></entry></feed>