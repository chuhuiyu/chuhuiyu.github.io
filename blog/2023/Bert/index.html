<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="bert--logbert">Bert &amp; LogBert</h1> <p>Owner: hui’yu c</p> <h1 id="1-general-knowledge-about-bert"><strong>1. General Knowledge about Bert</strong></h1> <p>Reference:</p> <ol> <li> <table> <tbody> <tr> <td>[Fine-tuning BERT for Text classification</td> <td>Kaggle](https://www.kaggle.com/code/neerajmohan/fine-tuning-bert-for-text-classification)</td> </tr> </tbody> </table> </li> <li>Natural Language Processing IN2361 by Prof. Dr. Georg Groh</li> </ol> <h2 id="bert-bidirectional-encoder-representations-from-transformers"><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong></h2> <p>Language modeling is a common method of pretraining on unlabeled text (self supervised learning). Most of the language models learned by iteratively predicting next word in a sequence auto regressively across enormous data sets of text like wikepedia. This can be left to right, right to left or bi-directional.</p> <p>There are two strategies of applying pretrained language representations to downstream tasks:</p> <ol> <li>Feature based approach</li> <li>Fine tuning approach</li> </ol> <p>The feauture based approach, such as <strong>ELMo</strong> uses task specific architectures that include the pretrained representations as additional features.</p> <p>The fine tuning approach, such as <strong>OpenAI GPT</strong>, introduces minimal task specific parameters, and is trained on the downstream task by fine tuning all the pretrained parameters.</p> <p>BERT model can be used for both the approaches. BERT reformulates the language modeling pretrained task of iteratively predicting the next word in sequence to instead <strong>incorporate bidirectional context and predict mask of intermediate tokens of the sequence and predict the mask token.</strong> BERT presented a new self supervised learning task for pretaining transformers in order to fine tune them for different tasks. They major difference between BERT and prior methods of pretraining transformer models is using the bidirectional context of language modeling. Most of the models either move left to right or right to left to predict next word in sequence, where BERT tries to learn intermediate tokens (by MASK), making the name Bidirectional Encoder.</p> <p>BERT uses Masked language model and also use “Next sentence prediction” task.</p> <p>BERT uses 3 embeddings to compute the input representations. They are token embeddings, segment embeddings and position embeddings.</p> <p>BERT Transformer will preserve the length of the (dimention of the) input. The final output will take this vector and pass these to seperate tasks (classification, in this case).</p> <p><img src="/assets/img/bert/Untitled.png" alt="Bert Training Process with masked language model"></p> <p>Bert Training Process with masked language model</p> <h2 id="bert-for-classification-logbert-didnt-use-this-strategy"><strong>BERT for Classification [LogBert didn’t use this strategy]</strong></h2> <p>BERT consists of stacked encoder layers. Just like the input of encoder of the transformer model, BERT model takes the sequence of numeric representation of the tokens as input. For classification tasks, we must prepend the special [CLS] token (classification token)to the beginning of every sentence.</p> <p>Encoder block of transformer outputs a vector with same length as of input. First position of the vector, corresponding to the [CLS] token, can now be used as the input for a classifier.</p> <p><img src="/assets/img/bert/Untitled1.png" alt="Bert for Classification"></p> <p>Bert for Classification</p> <h1 id="2-how-to-use-masked-langauge-model-to-do-anomaly-detection-logbert-method"><strong>2. How to use Masked Langauge Model to do Anomaly Detection [LogBert method]</strong></h1> <p>[Guo, Haixuan, Shuhan Yuan, and Xintao Wu. “Logbert: Log anomaly detection via bert.” <em>2021 international joint conference on neural networks (IJCNN)</em>. IEEE, 2021.]</p> <p><img src="/assets/img/bert/Untitled2.png" alt="Untitled"></p> <p>General Idea:</p> <ul> <li>Finetune the pretrained Bert model on the normal log lines by training on the masked language model.</li> <li>After this finetuning process, the model should predict the masked words in normal log lines very well. Since it didn’t see any abnormal logs before, it should predict the masked words in abnormal log lines very badly.</li> <li>From this point, we can seperate normal log lines and abnormal lines by looking at the performance of the model, which is reflected by the entropy loss value of prediction.</li> </ul> <h1 id="3-logbert-in-logai---the-whole-pipeline"><strong>3. LogBert in LogAI - the whole pipeline</strong></h1> <h2 id="31-load-opensearch-indices-preprocessing-and-save-as-pandas-feather-format"><strong>3.1 Load Opensearch indices, preprocessing and save as pandas “feather” format</strong></h2> <p>the util function that load data in range:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_data_range</span><span class="p">(</span><span class="n">index_name</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">client</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">client</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">client</span> <span class="o">=</span> <span class="nc">OpenSearch</span><span class="p">(</span>
            <span class="n">hosts</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">https://10.11.40.114:9200</span><span class="sh">'</span><span class="p">],</span>
            <span class="n">use_ssl</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">verify_certs</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
            <span class="n">http_auth</span><span class="o">=</span><span class="p">(</span><span class="sh">'</span><span class="s">admin</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">admin</span><span class="sh">'</span><span class="p">),</span>
            <span class="n">timeout</span><span class="o">=</span><span class="mi">60</span>
        <span class="p">)</span>
    <span class="n">max_index</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">indices</span><span class="p">.</span><span class="nf">stats</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index_name</span><span class="p">)[</span><span class="sh">'</span><span class="s">_all</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">primaries</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">docs</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">start</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">max_index</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="n">max_index</span><span class="p">)</span>

    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Loading data from index </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">start</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> until index </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">end</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> size is </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">query</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">from</span><span class="sh">"</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">size</span><span class="sh">"</span><span class="p">:</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">query</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">match_all</span><span class="sh">"</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
    <span class="p">}</span>

    <span class="n">search_results</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="n">query</span><span class="p">)</span>

<span class="c1"># Extract and convert the documents to a Pandas DataFrame
</span>    <span class="n">documents</span> <span class="o">=</span> <span class="n">search_results</span><span class="p">[</span><span class="sh">"</span><span class="s">hits</span><span class="sh">"</span><span class="p">][</span><span class="sh">"</span><span class="s">hits</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span><span class="p">[</span><span class="sh">'</span><span class="s">_source</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div> <p>init opensearch client, read the index in pieces and concat them together and save them:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">warnings</span>
<span class="kn">from</span> <span class="n">collections.abc</span> <span class="kn">import</span> <span class="n">MutableMapping</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">opensearchpy</span> <span class="kn">import</span> <span class="n">OpenSearch</span>
<span class="kn">import</span> <span class="n">math</span>
<span class="kn">import</span> <span class="n">pickle</span>
<span class="kn">import</span> <span class="n">utils</span>

<span class="n">client</span> <span class="o">=</span> <span class="nc">OpenSearch</span><span class="p">(</span>
    <span class="n">hosts</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">https://10.11.40.114:9200</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">use_ssl</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">verify_certs</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">http_auth</span><span class="o">=</span><span class="p">(</span><span class="sh">'</span><span class="s">admin</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">admin</span><span class="sh">'</span><span class="p">),</span>
    <span class="n">timeout</span><span class="o">=</span><span class="mi">60</span>
<span class="p">)</span>

<span class="n">index_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">2023-09-05_system_v4</span><span class="sh">"</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">indices</span><span class="p">.</span><span class="nf">stats</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index_name</span><span class="p">)[</span><span class="sh">'</span><span class="s">_all</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">primaries</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">docs</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">]</span>
<span class="n">iteration_size</span> <span class="o">=</span> <span class="mi">500000</span>
<span class="n">dataset_iterations</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">ceil</span><span class="p">((</span><span class="n">size</span> <span class="o">/</span> <span class="n">iteration_size</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">df size: </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> iterations: </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">dataset_iterations</span><span class="p">))</span>

<span class="n">df_save</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span>  <span class="n">dataset_iterations</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Iteration </span><span class="sh">"</span> <span class="o">+</span>  <span class="nf">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> of </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">dataset_iterations</span><span class="p">))</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">utils</span><span class="p">.</span><span class="nf">load_data_range</span><span class="p">(</span><span class="n">index_name</span><span class="p">,</span> <span class="p">(</span><span class="n">iteration_size</span> <span class="o">*</span> <span class="n">i</span><span class="p">),</span> <span class="p">((</span><span class="n">iteration_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">client</span><span class="p">)</span>
    <span class="n">df_save</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">df_save</span><span class="p">,</span> <span class="n">df</span><span class="p">])</span>

<span class="n">df_save</span> <span class="o">=</span> <span class="n">df_save</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="n">df_save</span><span class="p">.</span><span class="nf">to_feather</span><span class="p">(</span><span class="sh">'</span><span class="s">filename.feather</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>some preprocessing on the raw opensearch data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="c1">## read saved feather data
</span><span class="n">training_df1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_feather</span><span class="p">(</span><span class="sh">'</span><span class="s">filename1.feather</span><span class="sh">'</span><span class="p">)</span>
<span class="n">training_df2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_feather</span><span class="p">(</span><span class="sh">'</span><span class="s">filename2.feather</span><span class="sh">'</span><span class="p">)</span>
<span class="n">testing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_feather</span><span class="p">(</span><span class="sh">'</span><span class="s">filename3.feather</span><span class="sh">'</span><span class="p">)</span>

<span class="c1">## rename logline column from "desciption" to "logline", because logai uses constant## "logline" as the default column name of logline.
</span>
<span class="n">testing_df</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">},</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">training_df1</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">},</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">training_df2</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">},</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1">## set span_id
</span><span class="n">testing_df</span><span class="p">[</span><span class="sh">'</span><span class="s">span_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">testing_df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span>
<span class="n">training_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">span_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span>
<span class="n">training_df2</span><span class="p">[</span><span class="sh">'</span><span class="s">span_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_df2</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span>

<span class="c1">## label anomalies, note that the training process is purely unsupervised and## doesn't require labels, but it seems necessary to assign labels column to the## dataframe. Also it helps visualize the result later if you want to see the## loglines that you are interested in (just lable those interesting log lines with 1)## In normal cases, just set the whole columns 0 values
</span><span class="n">training_df1</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">training_df2</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">testing_df</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">testing_df</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="k">if</span> <span class="sh">"</span><span class="s">ABEND</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">]:</span>
        <span class="n">testing_df</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="sh">"</span><span class="s">ERROR</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">]:</span>
        <span class="n">testing_df</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="sh">"</span><span class="s">WARN</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">logline</span><span class="sh">'</span><span class="p">]:</span>
        <span class="n">testing_df</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">## concat 2 training dataframe as one and reset index, span_id
</span><span class="n">training_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">training_df1</span><span class="p">,</span><span class="n">training_df2</span><span class="p">]).</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="n">training_df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_df</span><span class="p">.</span><span class="n">index</span>
<span class="n">training_df</span><span class="p">[</span><span class="sh">'</span><span class="s">span_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span>
<span class="n">training_df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">level_0</span><span class="sh">'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">testing_df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">testing_df</span><span class="p">.</span><span class="n">index</span>
<span class="n">testing_df</span><span class="p">[</span><span class="sh">'</span><span class="s">span_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">testing_df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span>

<span class="c1">## save them again
</span><span class="n">testing_df</span><span class="p">.</span><span class="nf">to_pickle</span><span class="p">(</span><span class="sh">'</span><span class="s">testing_df.pkl</span><span class="sh">'</span><span class="p">)</span>
<span class="n">training_df</span><span class="p">.</span><span class="nf">to_pickle</span><span class="p">(</span><span class="sh">'</span><span class="s">training_df.pkl</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <h2 id="32-custom-preprocessor"><strong>3.2 Custom preprocessor</strong></h2> <p>read the saved pkl from the last step:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">testing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_pickle</span><span class="p">(</span><span class="sh">'</span><span class="s">testing_df.pkl</span><span class="sh">'</span><span class="p">)</span>
<span class="n">training_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_pickle</span><span class="p">(</span><span class="sh">'</span><span class="s">training_df.pkl</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>To encode special values (like IP, HEX value, INT value, etc.) into special tokens and preprocess , we need to override 2 methods from OpenSetPreprocessor, specify the preprocessor_config, and set special tokens in the tokenizer.</p> <h3 id="321-override-2-methods-from-opensetpreprocessor">3.2.1 Override 2 methods from OpenSetPreprocessor</h3> <ul> <li>_get_ids(self, logrecord) → pd.Series</li> <li>_get_labels(self, logrecord)</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">logai.preprocess.openset_preprocessor</span> <span class="kn">import</span> <span class="n">OpenSetPreprocessor</span>

<span class="k">class</span> <span class="nc">SDMLOG_Preprocessor</span><span class="p">(</span><span class="n">OpenSetPreprocessor</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Custom preprocessor for Open log dataset BGL.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">PreprocessorConfig</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_ids</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logrecord</span><span class="p">:</span> <span class="n">LogRecordObject</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Get ids of loglines.
        :param logrecord:  logrecord object containing the BGL data.
        :return: pd.Series object containing the ids of the loglines.
        </span><span class="sh">"""</span>
        <span class="n">ids</span> <span class="o">=</span> <span class="n">logrecord</span><span class="p">.</span><span class="n">span_id</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">SPAN_ID</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ids</span>

    <span class="k">def</span> <span class="nf">_get_labels</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logrecord</span><span class="p">:</span> <span class="n">LogRecordObject</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Get anomaly detection labels of loglines.
        :param logrecord: logrecord object containing the BGL data.
        :return:pd.Series object containing the labels of the loglines.
        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="n">logrecord</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="nc">SDMLOG_Preprocessor</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">preprocessor_config</span><span class="p">)</span>
<span class="n">preprocessed_filepath</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sh">'</span><span class="s">filename.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">logrecord</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="p">.</span><span class="nf">clean_log</span><span class="p">(</span><span class="n">logrecord</span><span class="p">)</span>
<span class="n">logrecord</span><span class="p">.</span><span class="nf">save_to_csv</span><span class="p">(</span><span class="n">preprocessed_filepath</span><span class="p">)</span>

</code></pre></div></div> <h3 id="322-specify-preprocessor-related-config">3.2.2 specify preprocessor-related config</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">preprocessor_config</span><span class="pi">:</span>
  <span class="na">custom_delimiters_regex</span><span class="pi">:</span>
              <span class="pi">[</span><span class="s1">'</span><span class="s">:'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">,'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">='</span><span class="pi">,</span> <span class="s1">'</span><span class="s">\\t'</span><span class="pi">]</span>
  <span class="na">custom_replace_list</span><span class="pi">:</span> <span class="pi">[</span>
              <span class="pi">[</span><span class="s1">'</span><span class="s">(0x)[0-9a-zA-Z]+'</span><span class="pi">,</span> <span class="s1">'</span><span class="nv"> </span><span class="s">HEX</span><span class="nv"> </span><span class="s">'</span><span class="pi">],</span>
              <span class="pi">[</span><span class="s1">'</span><span class="s">((?![A-Za-z]{8}|\\d{8})[A-Za-z\\d]{8})'</span><span class="pi">,</span> <span class="s1">'</span><span class="nv"> </span><span class="s">ALPHANUM</span><span class="nv"> </span><span class="s">'</span><span class="pi">],</span>
              <span class="pi">[</span><span class="s1">'</span><span class="s">\\d+.\\d+.\\d+.\\d+'</span><span class="pi">,</span> <span class="s1">'</span><span class="nv"> </span><span class="s">IP</span><span class="nv"> </span><span class="s">'</span><span class="pi">],</span>
              <span class="pi">[</span><span class="s1">'</span><span class="s">\\d+'</span><span class="pi">,</span> <span class="s1">'</span><span class="nv"> </span><span class="s">INT</span><span class="nv"> </span><span class="s">'</span><span class="pi">]</span>
          <span class="pi">]</span>

</code></pre></div></div> <h3 id="323-set-special-tokens-in-the-tokenizer-config-which-should-be-the-same-list-of-custom_replace_list-in-the-preprocessor_config">3.2.3 set special tokens in the tokenizer config, which should be the same list of “custom_replace_list” in the preprocessor_config</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">log_vectorizer_config</span><span class="pi">:</span>
  <span class="na">algo_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">logbert"</span>
  <span class="na">algo_param</span><span class="pi">:</span>
    <span class="na">model_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bert-base-cased"</span>
    <span class="na">max_token_len</span><span class="pi">:</span> <span class="m">120</span>
    <span class="na">custom_tokens</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">ALPHANUM"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">IP"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">HEX"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">INT"</span><span class="pi">]</span>
    <span class="na">output_dir</span><span class="pi">:</span> <span class="s2">"</span><span class="s">outputdir"</span>
    <span class="na">tokenizer_dirname</span><span class="pi">:</span> <span class="s2">"</span><span class="s">logbert_tokTenizer"</span>
</code></pre></div></div> <h2 id="33-split-the-training-validation-and-testing-dataset"><strong>3.3 Split the training, validation and testing dataset</strong></h2> <p>use sklearn.model_selection train_test_split:</p> <p>here I split the logrecord_training into 99% training data, and 1% evaluation data, for the sake of adequate amount of training data and quick evaluation</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">train_filepath</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sh">'</span><span class="s">train.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">dev_filepath</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sh">'</span><span class="s">dev.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">test_filepath</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sh">'</span><span class="s">test.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="n">train_ids</span><span class="p">,</span> <span class="n">dev_ids</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">dev_labels</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span>
    <span class="n">logrecord_training</span><span class="p">.</span><span class="n">span_id</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">SPAN_ID</span><span class="p">],</span>
    <span class="n">logrecord_training</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">],</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">indices_train</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span>
        <span class="n">logrecord_training</span><span class="p">.</span><span class="n">span_id</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span>
            <span class="n">logrecord_training</span><span class="p">.</span><span class="n">span_id</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">SPAN_ID</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">train_ids</span><span class="p">)</span>
        <span class="p">].</span><span class="n">index</span>
    <span class="p">)</span>
<span class="n">indices_dev</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span>
    <span class="n">logrecord_training</span><span class="p">.</span><span class="n">span_id</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">logrecord_training</span><span class="p">.</span><span class="n">span_id</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">SPAN_ID</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">dev_ids</span><span class="p">)].</span><span class="n">index</span>
<span class="p">)</span>
<span class="n">indices_test</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span>
    <span class="n">logrecord_testing</span><span class="p">.</span><span class="n">span_id</span><span class="p">.</span><span class="n">index</span>
<span class="p">)</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">logrecord_training</span><span class="p">.</span><span class="nf">select_by_index</span><span class="p">(</span><span class="n">indices_train</span><span class="p">)</span>
<span class="n">dev_data</span> <span class="o">=</span> <span class="n">logrecord_training</span><span class="p">.</span><span class="nf">select_by_index</span><span class="p">(</span><span class="n">indices_dev</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">logrecord_testing</span><span class="p">.</span><span class="nf">select_by_index</span><span class="p">(</span><span class="n">indices_test</span><span class="p">)</span>
<span class="c1">#train_data.save_to_csv(train_filepath)#dev_data.save_to_csv(dev_filepath)#test_data.save_to_csv(test_filepath)
</span><span class="nf">print </span><span class="p">(</span><span class="sh">'</span><span class="s">Train/Dev/Test Anomalous</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">train_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]),</span>
                                   <span class="nf">len</span><span class="p">(</span><span class="n">dev_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">dev_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]),</span>
                                   <span class="nf">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">test_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]))</span>
<span class="nf">print </span><span class="p">(</span><span class="sh">'</span><span class="s">Train/Dev/Test Normal</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">train_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]),</span>
                                   <span class="nf">len</span><span class="p">(</span><span class="n">dev_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">dev_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]),</span>
                                   <span class="nf">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">test_data</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LABELS</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]))</span>
</code></pre></div></div> <h2 id="34-train-bert-vectorizer"><strong>3.4 Train Bert vectorizer</strong></h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vectorizer</span> <span class="o">=</span> <span class="nc">LogVectorizer</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">log_vectorizer_config</span><span class="p">)</span>
<span class="n">vectorizer</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">dev_features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">dev_data</span><span class="p">)</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</code></pre></div></div> <h2 id="35-bert-model-training"><strong>3.5 Bert model training</strong></h2> <p>related config:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="na">nn_anomaly_detection_config</span><span class="pi">:</span>
      <span class="na">algo_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">logbert"</span>
      <span class="na">algo_params</span><span class="pi">:</span>
          <span class="na">model_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bert-base-cased"</span>
          <span class="na">learning_rate</span><span class="pi">:</span> <span class="m">0.00005</span>
          <span class="na">num_train_epochs</span><span class="pi">:</span> <span class="m">1</span>
          <span class="na">per_device_train_batch_size</span><span class="pi">:</span> <span class="m">32</span>
          <span class="na">max_token_len</span><span class="pi">:</span> <span class="m">120</span>
          <span class="na">save_steps</span><span class="pi">:</span> <span class="m">1000</span>
          <span class="na">eval_steps</span><span class="pi">:</span> <span class="m">1000</span>
          <span class="na">tokenizer_dirpath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bert-base-cased_tokenizer"</span>
          <span class="na">output_dir</span><span class="pi">:</span> <span class="s2">"</span><span class="s">outputdir"</span>
          <span class="s">pretrain_from_scratch:False</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">anomaly_detector</span> <span class="o">=</span> <span class="nc">NNAnomalyDetector</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">nn_anomaly_detection_config</span><span class="p">)</span>
<span class="n">anomaly_detector</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">dev_features</span><span class="p">)</span>
</code></pre></div></div> <h2 id="36-bert-model-testing"><strong>3.6 Bert model testing</strong></h2> <p>related config:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="na">nn_anomaly_detection_config</span><span class="pi">:</span>
      <span class="na">algo_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">logbert"</span>
      <span class="na">algo_params</span><span class="pi">:</span>
          <span class="na">model_name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bert-base-cased"</span>
          <span class="na">per_device_eval_batch_size</span><span class="pi">:</span> <span class="m">32</span>
          <span class="na">eval_accumulation_steps</span><span class="pi">:</span> <span class="m">284</span>
          <span class="na">mask_ngram</span><span class="pi">:</span> <span class="m">8</span>
          <span class="na">tokenizer_dirpath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bert-base-cased_tokenizer"</span>
          <span class="na">output_dir</span><span class="pi">:</span> <span class="s2">"</span><span class="s">outputdir"</span>
          <span class="na">num_eval_shards</span><span class="pi">:</span> <span class="m">100</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">anomaly_detector</span> <span class="o">=</span> <span class="nc">NNAnomalyDetector</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">nn_anomaly_detection_config</span><span class="p">)</span>
<span class="n">predict_results</span> <span class="o">=</span> <span class="n">anomaly_detector</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">test_features_piece</span><span class="p">)</span>
<span class="nf">print </span><span class="p">(</span><span class="n">predict_results</span><span class="p">)</span>
</code></pre></div></div> <h2 id="37-output-intepretation"><strong>3.7 Output Intepretation</strong></h2> <p>take partitioned logs as example, here is the data flow:</p> <ul> <li>prediction.feather <ul> <li>406105x19cols</li> <li>349 anomalies</li> </ul> </li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ Partitioner based on span_id, here span_id = seconds</code></p> <ul> <li>323 lines + labels(1 if merged lines contain anomalies otherwise 0)</li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ Train dev test split</code></p> <ul> <li> <p>splited result</p> <p>indices_train/dev/test: 181 20 122</p> </li> </ul> <p>Train/Dev/Test Anomalous: 0 0 71</p> <p>Train/Dev/Test Normal: 181 20 51</p> <p><code class="language-plaintext highlighter-rouge">↓ Turn pandas df into LogRecordObject</code></p> <ul> <li> <strong>LogRecordObject</strong> test_data, keys: [Timestamp, attributes, span_id, body, labels, _index]</li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ LogVectorizer</code></p> <ul> <li>test_features, features: [‘labels’, ‘input_ids’, ‘token_type_ids’, ‘attention_mask’], num_rows: <strong>122</strong> <ul> <li>for one row:<code class="language-plaintext highlighter-rouge">label: [1] input_ids size: 120 value: [[2, 1378, 584, 5, 1278, 855, 3, 1548, 855, 584, 5, 1278, 1287, 11, 11, 1729, 23, 50, 11, 401, 11, 1565, 11, 1287, 51, 139, 3, 1160, 855, 968, 821, 2087, 3, 576, 864, 454, 2075, 10, 2123, 17, 11, 182, 18, 3, 2082, 2107, 9, 2035, 312, 2126, 3, 1685, 1160, 1339, 3, 1685, 1339, 2119, 3, 2046, 1160, 2101, 3, 1965, 576, 2056, 10, 2027, 2055, 1010, 1964, 1691, 3, 1160, 855, 454, 908, 3, 42, 563, 406, 94, 75, 462, 216, 454, 1419, 206, 1041, 95, 85, 3, 182, 32, 549, 1650, 71, 9, 185, 454, 672, 264, 1693, 1346, 10, 1334, 139, 10, 139, 5, 1333, 139, 5, 393, 5, 408, 428, 1315, 11, 3]] token_type_ids size: 120 value: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] attention_mask size: 120 value: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</code> </li> </ul> </li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ NNAnomalyDetector.predict _generate_masked_input</code></p> <ul> <li> <p>mlm_dataset_test [masked language model]</p> <p>Dataset({ features: [‘labels’, ‘input_ids’, ‘token_type_ids’, ‘attention_mask’, ‘indices’], num_rows: <strong>1348</strong> })</p> <ul> <li>for one row:<code class="language-plaintext highlighter-rouge">Labels: [[-100, 1378, 584, -100, 1278, 855, -100, 1548, 855, 584, -100, 1278, 1287, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]] Input_ids size: 120 value: [[2, 4, 4, 5, 4, 4, 3, 4, 4, 4, 5, 4, 4, 11, 11, 1729, 23, 50, 11, 401, 11, 1565, 11, 1287, 51, 139, 3, 1160, 855, 968, 821, 2087, 3, 576, 864, 454, 2075, 10, 2123, 17, 11, 182, 18, 3, 2082, 2107, 9, 2035, 312, 2126, 3, 1685, 1160, 1339, 3, 1685, 1339, 2119, 3, 2046, 1160, 2101, 3, 1965, 576, 2056, 10, 2027, 2055, 1010, 1964, 1691, 3, 1160, 855, 454, 908, 3, 42, 563, 406, 94, 75, 462, 216, 454, 1419, 206, 1041, 95, 85, 3, 182, 32, 549, 1650, 71, 9, 185, 454, 672, 264, 1693, 1346, 10, 1334, 139, 10, 139, 5, 1333, 139, 5, 393, 5, 408, 428, 1315, 11, 3]] token_type_ids size: 120 value: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] attention_mask size: 120 value: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</code> </li> <li>what does _generate_masked_input do? <ul> <li>add masks on raw dataset:</li> <li><code class="language-plaintext highlighter-rouge">examples1 = {'input_ids' : [[10,5,7,-1,2]], 'attention_mask' : [[1,1,1,1,1]], 'token_type_ids' : [[0,0,0,0,0]]} indices = [0] output = generate_masked_input(examples1, indices) output {'input_ids': array([[ 4, 5, 7, -1, 2], [10, 4, 7, -1, 2], [10, 5, 4, -1, 2], [10, 5, 7, -1, 4]], dtype=int64), 'attention_mask': array([[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]), 'token_type_ids': array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]), 'labels': array([[ 10, -100, -100, -100, -100], [-100, 5, -100, -100, -100], [-100, -100, 7, -100, -100], [-100, -100, -100, -100, 2]]), 'indices': array([0, 0, 0, 0], dtype=int64)}</code></li> </ul> </li> </ul> </li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ NNAnomalyDetector.predict predict</code></p> <ul> <li> <p>test_results</p> <p>Test_results [‘predictions’, ‘label_ids’, ‘metrics’]</p> <ul> <li>Metrics: [‘test_loss’,’test_runtime’,’test_samples_per_second’,’test_steps_per_second]</li> <li> <p>One shard: [to avoid OOM, the whole mlm_dataset_test is split into 10 shards, and do prediction on each shard]</p> <p>Predictions.shape: (135,120,2220) Label_ids.shape: (135,120) 135*10-2 = 1348</p> </li> <li> <p>All result shape: (1348,120,2220)</p> <p>2220 is the volabulary size</p> <p>120 is the seq length</p> <p>1348 is the # of seqs</p> </li> <li> <p><strong>intepretation</strong><code class="language-plaintext highlighter-rouge">filtered_result = predict_result[5, [10,14,20,25], :] *# filtered_result has a shape of (4,2220)# for each 2220 vector, it shows the prob distribution of words behind this mask# you can get the output probability of real token_ids:* prob1 = predict_result[5,10,4] prob2 = predict_result[5,14,6] prob3 = predict_result[5,20,8] prob4 = predict_result[5,25,11] *# calculate cross entropy loss: -p*log(p)* entropy_i = -prob_i * log(prob_i) *# get a list of losses* entropies = [entropy1, entropy2, entropy3, entropy4, ...] *# calculate top 6 losses and take the mean of them as anomaly score:* anomaly score = mean(top6(entropies)) *# after this process, we can get a anomaly scores of shape (1348,)*</code></p> <p><strong>The Bert output has the same dimension of input, in this case the input is the mlm_dataset_test (1348,120), embed each token_id into 2220 dictionary vector, then it’s (1348,120, 2220), so the output is the same dimension of (1348,120,2220)</strong></p> <p><strong>for each log lines, we only need to calculate the loss function on the masked words, which were specified by a special token type [mask].</strong></p> <p><strong>for example, let’s assume in the masked logline 5, the index [10,14,20,25] are 4 words positions with [mask], and their token_ids are [4, 6, 8, 11]. We fetch those data out:</strong></p> </li> </ul> </li> </ul> <p><code class="language-plaintext highlighter-rouge">↓ anomaly_results.groupby('indices').mean()</code></p> <ul> <li>aggregate the anomaly score of the same index, calculate the mean of them as the final anomaly score of this log line.</li> </ul> <h2 id="38-the-code-modification-for-the-use-of-gpu-acceleration-and-no-partitioning"><strong>3.8 The code modification for the use of GPU acceleration and no partitioning</strong></h2> <ul> <li> <p>in logai\logai\algorithms\nn_model\logbert[train.py](http://train.py/):</p> <p>intend to use GPU if the environment has, not sure if this change is necessary, because I had experience that forgot to change train.py but still trained with GPU.</p> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>

<span class="k">def</span> <span class="nf">_initialize_trainer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">dev_dataset</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">initializing huggingface trainer object for logbert</span><span class="sh">"""</span>
        <span class="n">training_args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="n">model_dirpath</span><span class="p">,</span>
            <span class="n">evaluation_strategy</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">evaluation_strategy</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">num_train_epochs</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">logging_steps</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">per_device_train_batch_size</span><span class="p">,</span>
            <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">per_device_eval_batch_size</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">save_steps</span><span class="p">,</span>
            <span class="n">eval_steps</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">eval_steps</span><span class="p">,</span>
            <span class="n">resume_from_checkpoint</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">resume_from_checkpoint</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">data_collator</span> <span class="o">=</span> <span class="nc">DataCollatorForLanguageModeling</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">mlm_probability</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">mlm_probability</span><span class="p">,</span>
            <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">max_token_len</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1">## modified by huiyu
</span>        <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">():</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dev_dataset</span><span class="p">,</span>
                <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
                    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
                    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dev_dataset</span><span class="p">,</span>
                    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
            <span class="p">)</span>

</code></pre></div></div> <ul> <li>in logai\logai\algorithms\nn_model\logbert[predict.py](http://predict.py/): <ul> <li>I partitioned the log lines in the beginning because in the condition of no partitioning, during the execution of _generate_masked_input, it prompted an error “num_sections must be bigger than 0”, because there were cases that the whole log line contains purely so called special_token_ids.</li> <li>Added code ensures that lines with pure special tokens should return all labels with -100 so that they will not be taken into account when calculating the loss function in the later phase; in simple words, those lines will be neglected.</li> </ul> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_generate_masked_input</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">attention_masks</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">token_type_ids</span><span class="sh">"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="n">sliding_window_diag</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">input_ids</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">sliding_window_diag</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">examples</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">isin</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">special_token_ids</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">sliding_window_diag</span> <span class="o">=</span> <span class="n">sliding_window_diag</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">sliding_window_diag</span> <span class="o">=</span> <span class="n">sliding_window_diag</span><span class="p">[</span>
            <span class="o">~</span><span class="n">np</span><span class="p">.</span><span class="nf">all</span><span class="p">(</span><span class="n">sliding_window_diag</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="c1">## modified by huiyu
</span>        <span class="k">if</span> <span class="n">sliding_window_diag</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">])</span>
            <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">])</span>
            <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">token_type_ids</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="sh">'</span><span class="s">token_type_ids</span><span class="sh">'</span><span class="p">])</span>
            <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">indices</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">index</span><span class="p">]).</span><span class="nf">astype</span><span class="p">(</span>
                <span class="n">np</span><span class="p">.</span><span class="n">int64</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">output</span>
        <span class="c1">##
</span>        <span class="n">num_sections</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">sliding_window_diag</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">mask_ngram</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_sections</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">num_sections</span> <span class="o">=</span> <span class="n">sliding_window_diag</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">sliding_window_diag</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array_split</span><span class="p">(</span><span class="n">sliding_window_diag</span><span class="p">,</span> <span class="n">num_sections</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">diag</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">di</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">sliding_window_diag</span><span class="p">])</span>

        <span class="n">input_rpt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">tile</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="p">(</span><span class="n">diag</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">copy</span><span class="p">(</span><span class="n">input_rpt</span><span class="p">)</span>
        <span class="n">input_ids_masked</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_rpt</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">diag</span><span class="p">)</span> <span class="o">+</span> <span class="n">diag</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">mask_id</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="n">int64</span>
        <span class="p">)</span>
        <span class="n">attention_masks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">tile</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">attention_masks</span><span class="p">),</span> <span class="p">(</span><span class="n">input_ids_masked</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">tile</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">token_type_ids</span><span class="p">),</span> <span class="p">(</span><span class="n">input_ids_masked</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">labels</span><span class="p">[</span>
            <span class="n">input_ids_masked</span> <span class="o">!=</span> <span class="n">self</span><span class="p">.</span><span class="n">mask_id</span>
        <span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>  <span class="c1"># Need masked LM loss only for tokens with mask_id
</span>        <span class="n">examples</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_ids_masked</span>
        <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_masks</span>
        <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">token_type_ids</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">token_type_ids</span>
        <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">indices</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">index</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_ids_masked</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="nf">astype</span><span class="p">(</span>
            <span class="n">np</span><span class="p">.</span><span class="n">int64</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">examples</span>

</code></pre></div></div> <ul> <li> <p>in logai\logai\algorithms\vectorization_algo\logbert.py:</p> <p>This is one crutial change to the logai package. In the following _clean_dataset() method, log lines with pure special tokens will be excluded. The problem is that we don’t know the index of included lines when this function returns.</p> <ul> <li>To get the original indices, we need to return “old indices” from cleandataset() and return again in transform();</li> <li> <p>Also change the receiving params in fit(): cleaned_logrecord, _ = self._clean_dataset(logrecord)</p> <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>  <span class="c1">## modified by Huiyu
</span>  <span class="c1">## return indices from _clean_dataset, and return them in transform()
</span>  <span class="k">def</span> <span class="nf">_clean_dataset</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logrecord</span><span class="p">:</span> <span class="n">LogRecordObject</span><span class="p">):</span>
      <span class="n">special_tokens</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_all_special_tokens</span><span class="p">()</span>
      <span class="n">loglines</span> <span class="o">=</span> <span class="n">logrecord</span><span class="p">.</span><span class="n">body</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LOGLINE_NAME</span><span class="p">]</span>
      <span class="n">loglines_removed_special_tokens</span> <span class="o">=</span> <span class="n">loglines</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span>
          <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">))</span> <span class="o">-</span> <span class="nf">set</span><span class="p">(</span><span class="n">special_tokens</span><span class="p">)).</span><span class="nf">strip</span><span class="p">()</span>
      <span class="p">)</span>
      <span class="n">indices</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">logrecord</span><span class="p">.</span><span class="n">body</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">loglines_removed_special_tokens</span> <span class="o">!=</span> <span class="sh">""</span><span class="p">].</span><span class="n">index</span><span class="p">)</span>
        
      <span class="n">logrecord</span> <span class="o">=</span> <span class="n">logrecord</span><span class="p">.</span><span class="nf">select_by_index</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">logrecord</span><span class="p">,</span> <span class="n">indices</span>
        
  <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logrecord</span><span class="p">:</span> <span class="n">LogRecordObject</span><span class="p">):</span>
      <span class="sh">"""</span><span class="s">Transform method for running vectorizer over logrecord object.
        
      :param logrecord: A log record object containing the dataset
          to be vectorized.
      :return: HuggingFace dataset object.
      </span><span class="sh">"""</span>
      <span class="n">cleaned_logrecord</span><span class="p">,</span> <span class="n">old_indices</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_clean_dataset</span><span class="p">(</span><span class="n">logrecord</span><span class="p">)</span>
      <span class="n">dataset</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_hf_dataset</span><span class="p">(</span><span class="n">cleaned_logrecord</span><span class="p">)</span>
      <span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span>
          <span class="n">self</span><span class="p">.</span><span class="n">_tokenize_function</span><span class="p">,</span>
          <span class="n">batched</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
          <span class="n">num_proc</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">num_proc</span><span class="p">,</span>
          <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">constants</span><span class="p">.</span><span class="n">LOGLINE_NAME</span><span class="p">],</span>
      <span class="p">)</span>
      <span class="k">return</span> <span class="n">tokenized_dataset</span><span class="p">,</span> <span class="n">old_indices</span>
      <span class="c1">##
</span>        
  <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logrecord</span><span class="p">:</span> <span class="n">LogRecordObject</span><span class="p">):</span>
          <span class="sh">"""</span><span class="s">Fit method for training vectorizer for logbert.
        
          :param logrecord: A log record object containing the training
              dataset over which vectorizer is trained.
          </span><span class="sh">"""</span>
        
          <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">tokenizer_dirpath</span><span class="p">):</span>
              <span class="k">return</span>
  				<span class="c1">#also change here
</span>          <span class="n">cleaned_logrecord</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_clean_dataset</span><span class="p">(</span><span class="n">logrecord</span><span class="p">)</span>
          <span class="n">dataset</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_hf_dataset</span><span class="p">(</span><span class="n">cleaned_logrecord</span><span class="p">)</span>
        
          <span class="k">def</span> <span class="nf">batch_iterator</span><span class="p">():</span>
              <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">train_batch_size</span><span class="p">):</span>
                  <span class="k">yield</span> <span class="n">dataset</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">train_batch_size</span><span class="p">][</span>
                      <span class="n">constants</span><span class="p">.</span><span class="n">LOGLINE_NAME</span>
                  <span class="p">]</span>
        
          <span class="n">trainer</span> <span class="o">=</span> <span class="n">trainers</span><span class="p">.</span><span class="nc">WordPieceTrainer</span><span class="p">(</span>
              <span class="n">vocab_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">max_vocab_size</span><span class="p">,</span> <span class="n">special_tokens</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">special_tokens</span>
          <span class="p">)</span>
        
          <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">train_from_iterator</span><span class="p">(</span><span class="nf">batch_iterator</span><span class="p">(),</span> <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>
        
          <span class="n">cls_token_id</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">token_to_id</span><span class="p">(</span><span class="sh">"</span><span class="s">[CLS]</span><span class="sh">"</span><span class="p">)</span>
          <span class="n">sep_token_id</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">token_to_id</span><span class="p">(</span><span class="sh">"</span><span class="s">[SEP]</span><span class="sh">"</span><span class="p">)</span>
        
          <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">post_processor</span> <span class="o">=</span> <span class="n">processors</span><span class="p">.</span><span class="nc">TemplateProcessing</span><span class="p">(</span>
              <span class="n">single</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">[CLS]:0 $A:0 [SEP]:0</span><span class="sh">"</span><span class="p">,</span>
              <span class="n">pair</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1</span><span class="sh">"</span><span class="p">,</span>
              <span class="n">special_tokens</span><span class="o">=</span><span class="p">[</span>
                  <span class="p">(</span><span class="sh">"</span><span class="s">[CLS]</span><span class="sh">"</span><span class="p">,</span> <span class="n">cls_token_id</span><span class="p">),</span>
                  <span class="p">(</span><span class="sh">"</span><span class="s">[SEP]</span><span class="sh">"</span><span class="p">,</span> <span class="n">sep_token_id</span><span class="p">),</span>
              <span class="p">],</span>
          <span class="p">)</span>
        
          <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoders</span><span class="p">.</span><span class="nc">WordPiece</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="sh">"</span><span class="s">##</span><span class="sh">"</span><span class="p">)</span>
          <span class="n">new_tokenizer</span> <span class="o">=</span> <span class="nc">BertTokenizerFast</span><span class="p">(</span><span class="n">tokenizer_object</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">)</span>
        
          <span class="n">new_tokenizer</span><span class="p">.</span><span class="nf">save_pretrained</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">tokenizer_dirpath</span><span class="p">)</span>
          <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">new_tokenizer</span>
</code></pre></div> </div> </li> </ul> </li> </ul> </body></html>